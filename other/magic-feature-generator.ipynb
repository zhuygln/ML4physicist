{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1) Clean test from fake data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_kg_hide-input": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# coding: utf-8\n",
    "__author__ = 'ZFTurbo: https://kaggle.com/zfturbo'\n",
    "\n",
    "import numpy as np\n",
    "import gzip\n",
    "import pickle\n",
    "import os\n",
    "import glob\n",
    "import time\n",
    "import operator\n",
    "import pandas as pd\n",
    "from collections import Counter, defaultdict\n",
    "from multiprocessing import Process, Manager\n",
    "from sklearn.metrics import accuracy_score, log_loss, roc_auc_score\n",
    "import random\n",
    "import datetime\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt\n",
    "from sklearn.preprocessing import normalize\n",
    "from tqdm import tqdm\n",
    "import gc\n",
    "import psutil\n",
    "import warnings\n",
    "import shutil\n",
    "from keras.callbacks import Callback\n",
    "\n",
    "\n",
    "INPUT_PATH = '../input/'\n",
    "MODELS_PATH = './'\n",
    "OUTPUT_PATH = './'\n",
    "MODELS_PATH_KERAS = './'\n",
    "FEATURES_PATH = './'\n",
    "CACHE_PATH = './'\n",
    "SUBM_PATH = './'\n",
    "\n",
    "def read_train():\n",
    "    train = pd.read_csv(INPUT_PATH + 'train.csv', low_memory=True)\n",
    "    return train\n",
    "\n",
    "\n",
    "def read_test():\n",
    "    test = pd.read_csv(INPUT_PATH + 'test.csv', low_memory=True)\n",
    "    return test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "def get_real_test_data():\n",
    "    test = read_test()\n",
    "    ids = test['ID_code'].values.copy()\n",
    "    test.drop(['ID_code'], axis=1, inplace=True)\n",
    "    features = test.columns.values\n",
    "    df_test = test.values\n",
    "\n",
    "    unique_samples = []\n",
    "    unique_count = np.zeros_like(df_test)\n",
    "    for feature in tqdm(range(df_test.shape[1])):\n",
    "        _, index_, count_ = np.unique(df_test[:, feature], return_counts=True, return_index=True)\n",
    "        unique_count[index_[count_ == 1], feature] += 1\n",
    "\n",
    "    # Samples which have unique values are real the others are fake\n",
    "    real_samples_indexes = np.argwhere(np.sum(unique_count, axis=1) > 0)[:, 0]\n",
    "    synthetic_samples_indexes = np.argwhere(np.sum(unique_count, axis=1) == 0)[:, 0]\n",
    "\n",
    "    print(len(real_samples_indexes))\n",
    "    print(len(synthetic_samples_indexes))\n",
    "\n",
    "    test1 = read_test()\n",
    "    ids = ids[real_samples_indexes]\n",
    "    return ids\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2) Create Magic features**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "def get_magic_features():\n",
    "    d = dict()\n",
    "    for i in range(200):\n",
    "        d['var_{}'.format(i)] = np.str\n",
    "\n",
    "    train = pd.read_csv(INPUT_PATH + 'train.csv', dtype=d)\n",
    "    test = pd.read_csv(INPUT_PATH + 'test.csv', dtype=d)\n",
    "\n",
    "    real_ids = get_real_test_data()\n",
    "    test = test[test['ID_code'].isin(real_ids)]\n",
    "    print(len(test))\n",
    "    features = sorted(list(d.keys()))\n",
    "    print(train.shape, test.shape)\n",
    "    table = pd.concat((train[['ID_code'] + features], test[['ID_code'] + features]), axis=0)\n",
    "    print(table.shape)\n",
    "    feat_to_store = []\n",
    "    for f in features:\n",
    "        print('Go {}'.format(f))\n",
    "        new_feat = []\n",
    "        v = dict(pd.value_counts(table[f]))\n",
    "        for el in table[f].values:\n",
    "            new_feat.append(v[el])\n",
    "        table[f + '_counts_sum'] = new_feat\n",
    "        feat_to_store.append(f + '_counts_sum')\n",
    "\n",
    "    train = table[['ID_code'] + feat_to_store][:200000]\n",
    "    test = table[['ID_code'] + feat_to_store][200000:]\n",
    "    train.to_csv(FEATURES_PATH + 'counts_of_values_train.csv', index=False)\n",
    "    test.to_csv(FEATURES_PATH + 'counts_of_values_test.csv', index=False)\n",
    "    return train, test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3) Read data with magic features and create additional useful features var_N **mul** magic_N and var_N **div** magic_N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:05<00:00, 37.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100000\n",
      "100000\n",
      "100000\n",
      "(200000, 202) (100000, 201)\n",
      "(300000, 201)\n",
      "Go var_0\n",
      "Go var_1\n",
      "Go var_10\n",
      "Go var_100\n",
      "Go var_101\n",
      "Go var_102\n",
      "Go var_103\n",
      "Go var_104\n",
      "Go var_105\n",
      "Go var_106\n",
      "Go var_107\n",
      "Go var_108\n",
      "Go var_109\n",
      "Go var_11\n",
      "Go var_110\n",
      "Go var_111\n",
      "Go var_112\n",
      "Go var_113\n",
      "Go var_114\n",
      "Go var_115\n",
      "Go var_116\n",
      "Go var_117\n",
      "Go var_118\n",
      "Go var_119\n",
      "Go var_12\n",
      "Go var_120\n",
      "Go var_121\n",
      "Go var_122\n",
      "Go var_123\n",
      "Go var_124\n",
      "Go var_125\n",
      "Go var_126\n",
      "Go var_127\n",
      "Go var_128\n",
      "Go var_129\n",
      "Go var_13\n",
      "Go var_130\n",
      "Go var_131\n",
      "Go var_132\n",
      "Go var_133\n",
      "Go var_134\n",
      "Go var_135\n",
      "Go var_136\n",
      "Go var_137\n",
      "Go var_138\n",
      "Go var_139\n",
      "Go var_14\n",
      "Go var_140\n",
      "Go var_141\n",
      "Go var_142\n",
      "Go var_143\n",
      "Go var_144\n",
      "Go var_145\n",
      "Go var_146\n",
      "Go var_147\n",
      "Go var_148\n",
      "Go var_149\n",
      "Go var_15\n",
      "Go var_150\n",
      "Go var_151\n",
      "Go var_152\n",
      "Go var_153\n",
      "Go var_154\n",
      "Go var_155\n",
      "Go var_156\n",
      "Go var_157\n",
      "Go var_158\n",
      "Go var_159\n",
      "Go var_16\n",
      "Go var_160\n",
      "Go var_161\n",
      "Go var_162\n",
      "Go var_163\n",
      "Go var_164\n",
      "Go var_165\n",
      "Go var_166\n",
      "Go var_167\n",
      "Go var_168\n",
      "Go var_169\n",
      "Go var_17\n",
      "Go var_170\n",
      "Go var_171\n",
      "Go var_172\n",
      "Go var_173\n",
      "Go var_174\n",
      "Go var_175\n",
      "Go var_176\n",
      "Go var_177\n",
      "Go var_178\n",
      "Go var_179\n",
      "Go var_18\n",
      "Go var_180\n",
      "Go var_181\n",
      "Go var_182\n",
      "Go var_183\n",
      "Go var_184\n",
      "Go var_185\n",
      "Go var_186\n",
      "Go var_187\n",
      "Go var_188\n",
      "Go var_189\n",
      "Go var_19\n",
      "Go var_190\n",
      "Go var_191\n",
      "Go var_192\n",
      "Go var_193\n",
      "Go var_194\n",
      "Go var_195\n",
      "Go var_196\n",
      "Go var_197\n",
      "Go var_198\n",
      "Go var_199\n",
      "Go var_2\n",
      "Go var_20\n",
      "Go var_21\n",
      "Go var_22\n",
      "Go var_23\n",
      "Go var_24\n",
      "Go var_25\n",
      "Go var_26\n",
      "Go var_27\n",
      "Go var_28\n",
      "Go var_29\n",
      "Go var_3\n",
      "Go var_30\n",
      "Go var_31\n",
      "Go var_32\n",
      "Go var_33\n",
      "Go var_34\n",
      "Go var_35\n",
      "Go var_36\n",
      "Go var_37\n",
      "Go var_38\n",
      "Go var_39\n",
      "Go var_4\n",
      "Go var_40\n",
      "Go var_41\n",
      "Go var_42\n",
      "Go var_43\n",
      "Go var_44\n",
      "Go var_45\n",
      "Go var_46\n",
      "Go var_47\n",
      "Go var_48\n",
      "Go var_49\n",
      "Go var_5\n",
      "Go var_50\n",
      "Go var_51\n",
      "Go var_52\n",
      "Go var_53\n",
      "Go var_54\n",
      "Go var_55\n",
      "Go var_56\n",
      "Go var_57\n",
      "Go var_58\n",
      "Go var_59\n",
      "Go var_6\n",
      "Go var_60\n",
      "Go var_61\n",
      "Go var_62\n",
      "Go var_63\n",
      "Go var_64\n",
      "Go var_65\n",
      "Go var_66\n",
      "Go var_67\n",
      "Go var_68\n",
      "Go var_69\n",
      "Go var_7\n",
      "Go var_70\n",
      "Go var_71\n",
      "Go var_72\n",
      "Go var_73\n",
      "Go var_74\n",
      "Go var_75\n",
      "Go var_76\n",
      "Go var_77\n",
      "Go var_78\n",
      "Go var_79\n",
      "Go var_8\n",
      "Go var_80\n",
      "Go var_81\n",
      "Go var_82\n",
      "Go var_83\n",
      "Go var_84\n",
      "Go var_85\n",
      "Go var_86\n",
      "Go var_87\n",
      "Go var_88\n",
      "Go var_89\n",
      "Go var_9\n",
      "Go var_90\n",
      "Go var_91\n",
      "Go var_92\n",
      "Go var_93\n",
      "Go var_94\n",
      "Go var_95\n",
      "Go var_96\n",
      "Go var_97\n",
      "Go var_98\n",
      "Go var_99\n",
      "Features: [800] ['var_0', 'var_0_counts_sum', 'var_0_mul', 'var_0_div', 'var_1', 'var_1_counts_sum', 'var_1_mul', 'var_1_div', 'var_2', 'var_2_counts_sum', 'var_2_mul', 'var_2_div', 'var_3', 'var_3_counts_sum', 'var_3_mul', 'var_3_div', 'var_4', 'var_4_counts_sum', 'var_4_mul', 'var_4_div', 'var_5', 'var_5_counts_sum', 'var_5_mul', 'var_5_div', 'var_6', 'var_6_counts_sum', 'var_6_mul', 'var_6_div', 'var_7', 'var_7_counts_sum', 'var_7_mul', 'var_7_div', 'var_8', 'var_8_counts_sum', 'var_8_mul', 'var_8_div', 'var_9', 'var_9_counts_sum', 'var_9_mul', 'var_9_div', 'var_10', 'var_10_counts_sum', 'var_10_mul', 'var_10_div', 'var_11', 'var_11_counts_sum', 'var_11_mul', 'var_11_div', 'var_12', 'var_12_counts_sum', 'var_12_mul', 'var_12_div', 'var_13', 'var_13_counts_sum', 'var_13_mul', 'var_13_div', 'var_14', 'var_14_counts_sum', 'var_14_mul', 'var_14_div', 'var_15', 'var_15_counts_sum', 'var_15_mul', 'var_15_div', 'var_16', 'var_16_counts_sum', 'var_16_mul', 'var_16_div', 'var_17', 'var_17_counts_sum', 'var_17_mul', 'var_17_div', 'var_18', 'var_18_counts_sum', 'var_18_mul', 'var_18_div', 'var_19', 'var_19_counts_sum', 'var_19_mul', 'var_19_div', 'var_20', 'var_20_counts_sum', 'var_20_mul', 'var_20_div', 'var_21', 'var_21_counts_sum', 'var_21_mul', 'var_21_div', 'var_22', 'var_22_counts_sum', 'var_22_mul', 'var_22_div', 'var_23', 'var_23_counts_sum', 'var_23_mul', 'var_23_div', 'var_24', 'var_24_counts_sum', 'var_24_mul', 'var_24_div', 'var_25', 'var_25_counts_sum', 'var_25_mul', 'var_25_div', 'var_26', 'var_26_counts_sum', 'var_26_mul', 'var_26_div', 'var_27', 'var_27_counts_sum', 'var_27_mul', 'var_27_div', 'var_28', 'var_28_counts_sum', 'var_28_mul', 'var_28_div', 'var_29', 'var_29_counts_sum', 'var_29_mul', 'var_29_div', 'var_30', 'var_30_counts_sum', 'var_30_mul', 'var_30_div', 'var_31', 'var_31_counts_sum', 'var_31_mul', 'var_31_div', 'var_32', 'var_32_counts_sum', 'var_32_mul', 'var_32_div', 'var_33', 'var_33_counts_sum', 'var_33_mul', 'var_33_div', 'var_34', 'var_34_counts_sum', 'var_34_mul', 'var_34_div', 'var_35', 'var_35_counts_sum', 'var_35_mul', 'var_35_div', 'var_36', 'var_36_counts_sum', 'var_36_mul', 'var_36_div', 'var_37', 'var_37_counts_sum', 'var_37_mul', 'var_37_div', 'var_38', 'var_38_counts_sum', 'var_38_mul', 'var_38_div', 'var_39', 'var_39_counts_sum', 'var_39_mul', 'var_39_div', 'var_40', 'var_40_counts_sum', 'var_40_mul', 'var_40_div', 'var_41', 'var_41_counts_sum', 'var_41_mul', 'var_41_div', 'var_42', 'var_42_counts_sum', 'var_42_mul', 'var_42_div', 'var_43', 'var_43_counts_sum', 'var_43_mul', 'var_43_div', 'var_44', 'var_44_counts_sum', 'var_44_mul', 'var_44_div', 'var_45', 'var_45_counts_sum', 'var_45_mul', 'var_45_div', 'var_46', 'var_46_counts_sum', 'var_46_mul', 'var_46_div', 'var_47', 'var_47_counts_sum', 'var_47_mul', 'var_47_div', 'var_48', 'var_48_counts_sum', 'var_48_mul', 'var_48_div', 'var_49', 'var_49_counts_sum', 'var_49_mul', 'var_49_div', 'var_50', 'var_50_counts_sum', 'var_50_mul', 'var_50_div', 'var_51', 'var_51_counts_sum', 'var_51_mul', 'var_51_div', 'var_52', 'var_52_counts_sum', 'var_52_mul', 'var_52_div', 'var_53', 'var_53_counts_sum', 'var_53_mul', 'var_53_div', 'var_54', 'var_54_counts_sum', 'var_54_mul', 'var_54_div', 'var_55', 'var_55_counts_sum', 'var_55_mul', 'var_55_div', 'var_56', 'var_56_counts_sum', 'var_56_mul', 'var_56_div', 'var_57', 'var_57_counts_sum', 'var_57_mul', 'var_57_div', 'var_58', 'var_58_counts_sum', 'var_58_mul', 'var_58_div', 'var_59', 'var_59_counts_sum', 'var_59_mul', 'var_59_div', 'var_60', 'var_60_counts_sum', 'var_60_mul', 'var_60_div', 'var_61', 'var_61_counts_sum', 'var_61_mul', 'var_61_div', 'var_62', 'var_62_counts_sum', 'var_62_mul', 'var_62_div', 'var_63', 'var_63_counts_sum', 'var_63_mul', 'var_63_div', 'var_64', 'var_64_counts_sum', 'var_64_mul', 'var_64_div', 'var_65', 'var_65_counts_sum', 'var_65_mul', 'var_65_div', 'var_66', 'var_66_counts_sum', 'var_66_mul', 'var_66_div', 'var_67', 'var_67_counts_sum', 'var_67_mul', 'var_67_div', 'var_68', 'var_68_counts_sum', 'var_68_mul', 'var_68_div', 'var_69', 'var_69_counts_sum', 'var_69_mul', 'var_69_div', 'var_70', 'var_70_counts_sum', 'var_70_mul', 'var_70_div', 'var_71', 'var_71_counts_sum', 'var_71_mul', 'var_71_div', 'var_72', 'var_72_counts_sum', 'var_72_mul', 'var_72_div', 'var_73', 'var_73_counts_sum', 'var_73_mul', 'var_73_div', 'var_74', 'var_74_counts_sum', 'var_74_mul', 'var_74_div', 'var_75', 'var_75_counts_sum', 'var_75_mul', 'var_75_div', 'var_76', 'var_76_counts_sum', 'var_76_mul', 'var_76_div', 'var_77', 'var_77_counts_sum', 'var_77_mul', 'var_77_div', 'var_78', 'var_78_counts_sum', 'var_78_mul', 'var_78_div', 'var_79', 'var_79_counts_sum', 'var_79_mul', 'var_79_div', 'var_80', 'var_80_counts_sum', 'var_80_mul', 'var_80_div', 'var_81', 'var_81_counts_sum', 'var_81_mul', 'var_81_div', 'var_82', 'var_82_counts_sum', 'var_82_mul', 'var_82_div', 'var_83', 'var_83_counts_sum', 'var_83_mul', 'var_83_div', 'var_84', 'var_84_counts_sum', 'var_84_mul', 'var_84_div', 'var_85', 'var_85_counts_sum', 'var_85_mul', 'var_85_div', 'var_86', 'var_86_counts_sum', 'var_86_mul', 'var_86_div', 'var_87', 'var_87_counts_sum', 'var_87_mul', 'var_87_div', 'var_88', 'var_88_counts_sum', 'var_88_mul', 'var_88_div', 'var_89', 'var_89_counts_sum', 'var_89_mul', 'var_89_div', 'var_90', 'var_90_counts_sum', 'var_90_mul', 'var_90_div', 'var_91', 'var_91_counts_sum', 'var_91_mul', 'var_91_div', 'var_92', 'var_92_counts_sum', 'var_92_mul', 'var_92_div', 'var_93', 'var_93_counts_sum', 'var_93_mul', 'var_93_div', 'var_94', 'var_94_counts_sum', 'var_94_mul', 'var_94_div', 'var_95', 'var_95_counts_sum', 'var_95_mul', 'var_95_div', 'var_96', 'var_96_counts_sum', 'var_96_mul', 'var_96_div', 'var_97', 'var_97_counts_sum', 'var_97_mul', 'var_97_div', 'var_98', 'var_98_counts_sum', 'var_98_mul', 'var_98_div', 'var_99', 'var_99_counts_sum', 'var_99_mul', 'var_99_div', 'var_100', 'var_100_counts_sum', 'var_100_mul', 'var_100_div', 'var_101', 'var_101_counts_sum', 'var_101_mul', 'var_101_div', 'var_102', 'var_102_counts_sum', 'var_102_mul', 'var_102_div', 'var_103', 'var_103_counts_sum', 'var_103_mul', 'var_103_div', 'var_104', 'var_104_counts_sum', 'var_104_mul', 'var_104_div', 'var_105', 'var_105_counts_sum', 'var_105_mul', 'var_105_div', 'var_106', 'var_106_counts_sum', 'var_106_mul', 'var_106_div', 'var_107', 'var_107_counts_sum', 'var_107_mul', 'var_107_div', 'var_108', 'var_108_counts_sum', 'var_108_mul', 'var_108_div', 'var_109', 'var_109_counts_sum', 'var_109_mul', 'var_109_div', 'var_110', 'var_110_counts_sum', 'var_110_mul', 'var_110_div', 'var_111', 'var_111_counts_sum', 'var_111_mul', 'var_111_div', 'var_112', 'var_112_counts_sum', 'var_112_mul', 'var_112_div', 'var_113', 'var_113_counts_sum', 'var_113_mul', 'var_113_div', 'var_114', 'var_114_counts_sum', 'var_114_mul', 'var_114_div', 'var_115', 'var_115_counts_sum', 'var_115_mul', 'var_115_div', 'var_116', 'var_116_counts_sum', 'var_116_mul', 'var_116_div', 'var_117', 'var_117_counts_sum', 'var_117_mul', 'var_117_div', 'var_118', 'var_118_counts_sum', 'var_118_mul', 'var_118_div', 'var_119', 'var_119_counts_sum', 'var_119_mul', 'var_119_div', 'var_120', 'var_120_counts_sum', 'var_120_mul', 'var_120_div', 'var_121', 'var_121_counts_sum', 'var_121_mul', 'var_121_div', 'var_122', 'var_122_counts_sum', 'var_122_mul', 'var_122_div', 'var_123', 'var_123_counts_sum', 'var_123_mul', 'var_123_div', 'var_124', 'var_124_counts_sum', 'var_124_mul', 'var_124_div', 'var_125', 'var_125_counts_sum', 'var_125_mul', 'var_125_div', 'var_126', 'var_126_counts_sum', 'var_126_mul', 'var_126_div', 'var_127', 'var_127_counts_sum', 'var_127_mul', 'var_127_div', 'var_128', 'var_128_counts_sum', 'var_128_mul', 'var_128_div', 'var_129', 'var_129_counts_sum', 'var_129_mul', 'var_129_div', 'var_130', 'var_130_counts_sum', 'var_130_mul', 'var_130_div', 'var_131', 'var_131_counts_sum', 'var_131_mul', 'var_131_div', 'var_132', 'var_132_counts_sum', 'var_132_mul', 'var_132_div', 'var_133', 'var_133_counts_sum', 'var_133_mul', 'var_133_div', 'var_134', 'var_134_counts_sum', 'var_134_mul', 'var_134_div', 'var_135', 'var_135_counts_sum', 'var_135_mul', 'var_135_div', 'var_136', 'var_136_counts_sum', 'var_136_mul', 'var_136_div', 'var_137', 'var_137_counts_sum', 'var_137_mul', 'var_137_div', 'var_138', 'var_138_counts_sum', 'var_138_mul', 'var_138_div', 'var_139', 'var_139_counts_sum', 'var_139_mul', 'var_139_div', 'var_140', 'var_140_counts_sum', 'var_140_mul', 'var_140_div', 'var_141', 'var_141_counts_sum', 'var_141_mul', 'var_141_div', 'var_142', 'var_142_counts_sum', 'var_142_mul', 'var_142_div', 'var_143', 'var_143_counts_sum', 'var_143_mul', 'var_143_div', 'var_144', 'var_144_counts_sum', 'var_144_mul', 'var_144_div', 'var_145', 'var_145_counts_sum', 'var_145_mul', 'var_145_div', 'var_146', 'var_146_counts_sum', 'var_146_mul', 'var_146_div', 'var_147', 'var_147_counts_sum', 'var_147_mul', 'var_147_div', 'var_148', 'var_148_counts_sum', 'var_148_mul', 'var_148_div', 'var_149', 'var_149_counts_sum', 'var_149_mul', 'var_149_div', 'var_150', 'var_150_counts_sum', 'var_150_mul', 'var_150_div', 'var_151', 'var_151_counts_sum', 'var_151_mul', 'var_151_div', 'var_152', 'var_152_counts_sum', 'var_152_mul', 'var_152_div', 'var_153', 'var_153_counts_sum', 'var_153_mul', 'var_153_div', 'var_154', 'var_154_counts_sum', 'var_154_mul', 'var_154_div', 'var_155', 'var_155_counts_sum', 'var_155_mul', 'var_155_div', 'var_156', 'var_156_counts_sum', 'var_156_mul', 'var_156_div', 'var_157', 'var_157_counts_sum', 'var_157_mul', 'var_157_div', 'var_158', 'var_158_counts_sum', 'var_158_mul', 'var_158_div', 'var_159', 'var_159_counts_sum', 'var_159_mul', 'var_159_div', 'var_160', 'var_160_counts_sum', 'var_160_mul', 'var_160_div', 'var_161', 'var_161_counts_sum', 'var_161_mul', 'var_161_div', 'var_162', 'var_162_counts_sum', 'var_162_mul', 'var_162_div', 'var_163', 'var_163_counts_sum', 'var_163_mul', 'var_163_div', 'var_164', 'var_164_counts_sum', 'var_164_mul', 'var_164_div', 'var_165', 'var_165_counts_sum', 'var_165_mul', 'var_165_div', 'var_166', 'var_166_counts_sum', 'var_166_mul', 'var_166_div', 'var_167', 'var_167_counts_sum', 'var_167_mul', 'var_167_div', 'var_168', 'var_168_counts_sum', 'var_168_mul', 'var_168_div', 'var_169', 'var_169_counts_sum', 'var_169_mul', 'var_169_div', 'var_170', 'var_170_counts_sum', 'var_170_mul', 'var_170_div', 'var_171', 'var_171_counts_sum', 'var_171_mul', 'var_171_div', 'var_172', 'var_172_counts_sum', 'var_172_mul', 'var_172_div', 'var_173', 'var_173_counts_sum', 'var_173_mul', 'var_173_div', 'var_174', 'var_174_counts_sum', 'var_174_mul', 'var_174_div', 'var_175', 'var_175_counts_sum', 'var_175_mul', 'var_175_div', 'var_176', 'var_176_counts_sum', 'var_176_mul', 'var_176_div', 'var_177', 'var_177_counts_sum', 'var_177_mul', 'var_177_div', 'var_178', 'var_178_counts_sum', 'var_178_mul', 'var_178_div', 'var_179', 'var_179_counts_sum', 'var_179_mul', 'var_179_div', 'var_180', 'var_180_counts_sum', 'var_180_mul', 'var_180_div', 'var_181', 'var_181_counts_sum', 'var_181_mul', 'var_181_div', 'var_182', 'var_182_counts_sum', 'var_182_mul', 'var_182_div', 'var_183', 'var_183_counts_sum', 'var_183_mul', 'var_183_div', 'var_184', 'var_184_counts_sum', 'var_184_mul', 'var_184_div', 'var_185', 'var_185_counts_sum', 'var_185_mul', 'var_185_div', 'var_186', 'var_186_counts_sum', 'var_186_mul', 'var_186_div', 'var_187', 'var_187_counts_sum', 'var_187_mul', 'var_187_div', 'var_188', 'var_188_counts_sum', 'var_188_mul', 'var_188_div', 'var_189', 'var_189_counts_sum', 'var_189_mul', 'var_189_div', 'var_190', 'var_190_counts_sum', 'var_190_mul', 'var_190_div', 'var_191', 'var_191_counts_sum', 'var_191_mul', 'var_191_div', 'var_192', 'var_192_counts_sum', 'var_192_mul', 'var_192_div', 'var_193', 'var_193_counts_sum', 'var_193_mul', 'var_193_div', 'var_194', 'var_194_counts_sum', 'var_194_mul', 'var_194_div', 'var_195', 'var_195_counts_sum', 'var_195_mul', 'var_195_div', 'var_196', 'var_196_counts_sum', 'var_196_mul', 'var_196_div', 'var_197', 'var_197_counts_sum', 'var_197_mul', 'var_197_div', 'var_198', 'var_198_counts_sum', 'var_198_mul', 'var_198_div', 'var_199', 'var_199_counts_sum', 'var_199_mul', 'var_199_div']\n"
     ]
    }
   ],
   "source": [
    "train = read_train()\n",
    "test = read_test()\n",
    "\n",
    "t1, t2 = get_magic_features()\n",
    "train = train.merge(t1, on='ID_code', how='left')\n",
    "test = test.merge(t2, on='ID_code', how='left')\n",
    "f_add = list(t1.columns.values)\n",
    "f_add.remove('ID_code')\n",
    "test.fillna(-1, inplace=True)\n",
    "\n",
    "for i in range(200):\n",
    "    train['var_{}_mul'.format(i)] = train['var_{}'.format(i)] * train['var_{}_counts_sum'.format(i)]\n",
    "    test['var_{}_mul'.format(i)] = test['var_{}'.format(i)] * test['var_{}_counts_sum'.format(i)]\n",
    "    train['var_{}_div'.format(i)] = train['var_{}'.format(i)] / train['var_{}_counts_sum'.format(i)]\n",
    "    test['var_{}_div'.format(i)] = test['var_{}'.format(i)] / test['var_{}_counts_sum'.format(i)]\n",
    "\n",
    "features = []\n",
    "for i in range(200):\n",
    "    features.append('var_{}'.format(i))\n",
    "    features.append('var_{}_counts_sum'.format(i))\n",
    "    features.append('var_{}_mul'.format(i))\n",
    "    features.append('var_{}_div'.format(i))\n",
    "print('Features: [{}] {}'.format(len(features), features))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4) Create model\n",
    "\n",
    "5) Use random shuffle of columns during training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start fold 1\n",
      "Train data: (159999, 802) (159999,)\n",
      "Valid data: (40001, 802) (40001,)\n",
      "Train data: (159999, 800) (159999,)\n",
      "Valid data: (40001, 800) (40001,)\n",
      "Valid sum: 4020\n",
      "Batch size: 1000\n",
      "Learning rate: 0.002\n",
      "Steps train: 159, Steps valid: 1\n",
      "WARNING:tensorflow:From /opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 800, 1)            0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 800, 1)            3200      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 800, 128)          256       \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 102400)            0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 102401    \n",
      "=================================================================\n",
      "Total params: 105,857\n",
      "Trainable params: 104,257\n",
      "Non-trainable params: 1,600\n",
      "_________________________________________________________________\n",
      "None\n",
      "Model memory usage: 0.769 GB\n",
      "WARNING:tensorflow:From /opt/conda/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/50\n",
      " - 15s - loss: 0.3058 - acc: 0.9024 - val_loss: 0.2161 - val_acc: 0.9160\n",
      "AUC score: 0.877539\n",
      "Epoch 2/50\n",
      " - 12s - loss: 0.2155 - acc: 0.9197 - val_loss: 0.2417 - val_acc: 0.9040\n",
      "AUC score: 0.888714\n",
      "Epoch 3/50\n",
      " - 13s - loss: 0.2093 - acc: 0.9226 - val_loss: 0.2081 - val_acc: 0.9210\n",
      "AUC score: 0.893596\n",
      "Epoch 4/50\n",
      " - 12s - loss: 0.2021 - acc: 0.9250 - val_loss: 0.2062 - val_acc: 0.9280\n",
      "AUC score: 0.899076\n",
      "Epoch 5/50\n",
      " - 12s - loss: 0.1983 - acc: 0.9266 - val_loss: 0.1899 - val_acc: 0.9260\n",
      "AUC score: 0.904311\n",
      "Epoch 6/50\n",
      " - 12s - loss: 0.1931 - acc: 0.9280 - val_loss: 0.1901 - val_acc: 0.9270\n",
      "AUC score: 0.908264\n",
      "Epoch 7/50\n",
      " - 11s - loss: 0.1892 - acc: 0.9301 - val_loss: 0.2028 - val_acc: 0.9210\n",
      "AUC score: 0.911629\n",
      "Epoch 8/50\n",
      " - 11s - loss: 0.1870 - acc: 0.9311 - val_loss: 0.1811 - val_acc: 0.9360\n",
      "AUC score: 0.910819\n",
      "Epoch 9/50\n",
      " - 12s - loss: 0.1875 - acc: 0.9305 - val_loss: 0.1801 - val_acc: 0.9300\n",
      "AUC score: 0.913035\n",
      "Epoch 10/50\n",
      " - 12s - loss: 0.1868 - acc: 0.9313 - val_loss: 0.1911 - val_acc: 0.9360\n",
      "AUC score: 0.914651\n",
      "Epoch 11/50\n",
      " - 12s - loss: 0.1855 - acc: 0.9317 - val_loss: 0.1545 - val_acc: 0.9420\n",
      "AUC score: 0.914956\n",
      "Epoch 12/50\n",
      " - 12s - loss: 0.1827 - acc: 0.9325 - val_loss: 0.1940 - val_acc: 0.9270\n",
      "AUC score: 0.915391\n",
      "Epoch 13/50\n",
      " - 12s - loss: 0.1870 - acc: 0.9309 - val_loss: 0.1851 - val_acc: 0.9300\n",
      "AUC score: 0.916353\n",
      "Epoch 14/50\n",
      " - 12s - loss: 0.1841 - acc: 0.9318 - val_loss: 0.1999 - val_acc: 0.9200\n",
      "AUC score: 0.916056\n",
      "Epoch 15/50\n",
      " - 12s - loss: 0.1836 - acc: 0.9327 - val_loss: 0.1862 - val_acc: 0.9280\n",
      "AUC score: 0.915834\n",
      "Epoch 16/50\n",
      " - 12s - loss: 0.1806 - acc: 0.9331 - val_loss: 0.1913 - val_acc: 0.9270\n",
      "AUC score: 0.916837\n",
      "Epoch 17/50\n",
      " - 12s - loss: 0.1809 - acc: 0.9331 - val_loss: 0.2324 - val_acc: 0.9140\n",
      "AUC score: 0.916288\n",
      "Epoch 18/50\n",
      " - 11s - loss: 0.1806 - acc: 0.9331 - val_loss: 0.1944 - val_acc: 0.9230\n",
      "AUC score: 0.917256\n",
      "Epoch 19/50\n",
      " - 12s - loss: 0.1804 - acc: 0.9333 - val_loss: 0.1578 - val_acc: 0.9430\n",
      "AUC score: 0.918166\n",
      "Epoch 20/50\n",
      " - 11s - loss: 0.1796 - acc: 0.9334 - val_loss: 0.1599 - val_acc: 0.9450\n",
      "AUC score: 0.917749\n",
      "Epoch 21/50\n",
      " - 11s - loss: 0.1820 - acc: 0.9322 - val_loss: 0.1619 - val_acc: 0.9370\n",
      "AUC score: 0.917417\n",
      "Epoch 22/50\n",
      " - 13s - loss: 0.1813 - acc: 0.9327 - val_loss: 0.1899 - val_acc: 0.9240\n",
      "AUC score: 0.918147\n",
      "Epoch 23/50\n",
      " - 12s - loss: 0.1794 - acc: 0.9333 - val_loss: 0.1767 - val_acc: 0.9300\n",
      "AUC score: 0.918689\n",
      "Epoch 24/50\n",
      " - 12s - loss: 0.1812 - acc: 0.9333 - val_loss: 0.1707 - val_acc: 0.9360\n",
      "AUC score: 0.917810\n",
      "Epoch 25/50\n",
      " - 12s - loss: 0.1770 - acc: 0.9346 - val_loss: 0.1708 - val_acc: 0.9400\n",
      "AUC score: 0.918960\n",
      "Epoch 26/50\n",
      " - 11s - loss: 0.1797 - acc: 0.9334 - val_loss: 0.1801 - val_acc: 0.9320\n",
      "AUC score: 0.918211\n",
      "Epoch 27/50\n",
      " - 12s - loss: 0.1799 - acc: 0.9337 - val_loss: 0.1965 - val_acc: 0.9320\n",
      "AUC score: 0.918523\n",
      "Epoch 28/50\n",
      " - 12s - loss: 0.1774 - acc: 0.9348 - val_loss: 0.1949 - val_acc: 0.9190\n",
      "AUC score: 0.918691\n",
      "Epoch 29/50\n",
      " - 12s - loss: 0.1774 - acc: 0.9341 - val_loss: 0.1913 - val_acc: 0.9220\n",
      "AUC score: 0.919141\n",
      "Epoch 30/50\n",
      " - 12s - loss: 0.1766 - acc: 0.9353 - val_loss: 0.1587 - val_acc: 0.9430\n",
      "AUC score: 0.918143\n",
      "Epoch 31/50\n",
      " - 12s - loss: 0.1776 - acc: 0.9340 - val_loss: 0.1675 - val_acc: 0.9380\n",
      "AUC score: 0.918953\n",
      "Epoch 32/50\n",
      " - 12s - loss: 0.1785 - acc: 0.9347 - val_loss: 0.1712 - val_acc: 0.9400\n",
      "AUC score: 0.919131\n",
      "Epoch 33/50\n",
      " - 11s - loss: 0.1783 - acc: 0.9337 - val_loss: 0.2143 - val_acc: 0.9210\n",
      "AUC score: 0.919508\n",
      "Epoch 34/50\n",
      " - 12s - loss: 0.1778 - acc: 0.9342 - val_loss: 0.1950 - val_acc: 0.9220\n",
      "AUC score: 0.918810\n",
      "Epoch 35/50\n",
      " - 12s - loss: 0.1776 - acc: 0.9344 - val_loss: 0.1536 - val_acc: 0.9450\n",
      "AUC score: 0.919311\n",
      "\n",
      "Epoch 00035: ReduceLROnPlateau reducing learning rate to 0.0019000000902451575.\n",
      "Epoch 36/50\n",
      " - 12s - loss: 0.1768 - acc: 0.9346 - val_loss: 0.2100 - val_acc: 0.9150\n",
      "AUC score: 0.920056\n",
      "Epoch 37/50\n",
      " - 12s - loss: 0.1764 - acc: 0.9344 - val_loss: 0.1934 - val_acc: 0.9320\n",
      "AUC score: 0.919408\n",
      "Epoch 38/50\n",
      " - 11s - loss: 0.1747 - acc: 0.9350 - val_loss: 0.2238 - val_acc: 0.9170\n",
      "AUC score: 0.920330\n",
      "Epoch 39/50\n",
      " - 12s - loss: 0.1783 - acc: 0.9344 - val_loss: 0.2089 - val_acc: 0.9200\n",
      "AUC score: 0.918728\n",
      "Epoch 40/50\n",
      " - 12s - loss: 0.1762 - acc: 0.9345 - val_loss: 0.1662 - val_acc: 0.9430\n",
      "AUC score: 0.919957\n",
      "Epoch 41/50\n",
      " - 13s - loss: 0.1758 - acc: 0.9350 - val_loss: 0.1849 - val_acc: 0.9400\n",
      "AUC score: 0.920061\n",
      "Epoch 42/50\n",
      " - 12s - loss: 0.1746 - acc: 0.9349 - val_loss: 0.1856 - val_acc: 0.9320\n",
      "AUC score: 0.920544\n",
      "Epoch 43/50\n",
      " - 12s - loss: 0.1732 - acc: 0.9357 - val_loss: 0.1869 - val_acc: 0.9320\n",
      "AUC score: 0.919755\n",
      "Epoch 44/50\n",
      " - 12s - loss: 0.1756 - acc: 0.9352 - val_loss: 0.1752 - val_acc: 0.9300\n",
      "AUC score: 0.919467\n",
      "Epoch 45/50\n",
      " - 12s - loss: 0.1747 - acc: 0.9351 - val_loss: 0.2095 - val_acc: 0.9300\n",
      "AUC score: 0.920252\n",
      "Epoch 46/50\n",
      " - 12s - loss: 0.1736 - acc: 0.9356 - val_loss: 0.2066 - val_acc: 0.9220\n",
      "AUC score: 0.919887\n",
      "Epoch 47/50\n",
      " - 12s - loss: 0.1749 - acc: 0.9347 - val_loss: 0.1665 - val_acc: 0.9380\n",
      "AUC score: 0.921297\n",
      "Epoch 48/50\n",
      " - 12s - loss: 0.1731 - acc: 0.9359 - val_loss: 0.1738 - val_acc: 0.9370\n",
      "AUC score: 0.920912\n",
      "Epoch 49/50\n",
      " - 12s - loss: 0.1750 - acc: 0.9355 - val_loss: 0.1725 - val_acc: 0.9360\n",
      "AUC score: 0.919792\n",
      "Epoch 50/50\n",
      " - 12s - loss: 0.1750 - acc: 0.9349 - val_loss: 0.2070 - val_acc: 0.9200\n",
      "AUC score: 0.920337\n",
      "Minimum loss for given fold:  0.15357324481010437\n",
      "Fold 1 score: 0.921297\n",
      "Start fold 2\n",
      "Train data: (159999, 802) (159999,)\n",
      "Valid data: (40001, 802) (40001,)\n",
      "Train data: (159999, 800) (159999,)\n",
      "Valid data: (40001, 800) (40001,)\n",
      "Valid sum: 4020\n",
      "Batch size: 1000\n",
      "Learning rate: 0.002\n",
      "Steps train: 159, Steps valid: 1\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         (None, 800, 1)            0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 800, 1)            3200      \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 800, 128)          256       \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 102400)            0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 1)                 102401    \n",
      "=================================================================\n",
      "Total params: 105,857\n",
      "Trainable params: 104,257\n",
      "Non-trainable params: 1,600\n",
      "_________________________________________________________________\n",
      "None\n",
      "Model memory usage: 0.769 GB\n",
      "Epoch 1/50\n",
      " - 11s - loss: 0.2994 - acc: 0.9064 - val_loss: 0.2329 - val_acc: 0.9110\n",
      "AUC score: 0.867450\n",
      "Epoch 2/50\n",
      " - 10s - loss: 0.2156 - acc: 0.9193 - val_loss: 0.1931 - val_acc: 0.9250\n",
      "AUC score: 0.879333\n",
      "Epoch 3/50\n",
      " - 11s - loss: 0.2091 - acc: 0.9221 - val_loss: 0.2205 - val_acc: 0.9100\n",
      "AUC score: 0.886882\n",
      "Epoch 4/50\n",
      " - 11s - loss: 0.2020 - acc: 0.9250 - val_loss: 0.2260 - val_acc: 0.9140\n",
      "AUC score: 0.893564\n",
      "Epoch 5/50\n",
      " - 10s - loss: 0.1965 - acc: 0.9270 - val_loss: 0.1839 - val_acc: 0.9350\n",
      "AUC score: 0.898109\n",
      "Epoch 6/50\n",
      " - 10s - loss: 0.1900 - acc: 0.9297 - val_loss: 0.2029 - val_acc: 0.9240\n",
      "AUC score: 0.901111\n",
      "Epoch 7/50\n",
      " - 10s - loss: 0.1921 - acc: 0.9288 - val_loss: 0.1807 - val_acc: 0.9380\n",
      "AUC score: 0.903256\n",
      "Epoch 8/50\n",
      " - 10s - loss: 0.1869 - acc: 0.9306 - val_loss: 0.2065 - val_acc: 0.9170\n",
      "AUC score: 0.905087\n",
      "Epoch 9/50\n",
      " - 10s - loss: 0.1865 - acc: 0.9311 - val_loss: 0.1947 - val_acc: 0.9250\n",
      "AUC score: 0.905952\n",
      "Epoch 10/50\n",
      " - 10s - loss: 0.1845 - acc: 0.9318 - val_loss: 0.1891 - val_acc: 0.9310\n",
      "AUC score: 0.907401\n",
      "Epoch 11/50\n",
      " - 10s - loss: 0.1864 - acc: 0.9318 - val_loss: 0.1715 - val_acc: 0.9320\n",
      "AUC score: 0.907868\n",
      "Epoch 12/50\n",
      " - 10s - loss: 0.1821 - acc: 0.9325 - val_loss: 0.1636 - val_acc: 0.9340\n",
      "AUC score: 0.908922\n",
      "Epoch 13/50\n",
      " - 10s - loss: 0.1810 - acc: 0.9338 - val_loss: 0.1960 - val_acc: 0.9270\n",
      "AUC score: 0.909050\n",
      "Epoch 14/50\n",
      " - 10s - loss: 0.1785 - acc: 0.9343 - val_loss: 0.2302 - val_acc: 0.9140\n",
      "AUC score: 0.908931\n",
      "Epoch 15/50\n",
      " - 10s - loss: 0.1809 - acc: 0.9329 - val_loss: 0.2090 - val_acc: 0.9290\n",
      "AUC score: 0.909484\n",
      "Epoch 16/50\n",
      " - 10s - loss: 0.1797 - acc: 0.9333 - val_loss: 0.2392 - val_acc: 0.9100\n",
      "AUC score: 0.909757\n",
      "Epoch 17/50\n",
      " - 10s - loss: 0.1786 - acc: 0.9338 - val_loss: 0.1605 - val_acc: 0.9460\n",
      "AUC score: 0.911252\n",
      "Epoch 18/50\n",
      " - 10s - loss: 0.1802 - acc: 0.9336 - val_loss: 0.1928 - val_acc: 0.9290\n",
      "AUC score: 0.911401\n",
      "Epoch 19/50\n",
      " - 11s - loss: 0.1826 - acc: 0.9318 - val_loss: 0.1848 - val_acc: 0.9360\n",
      "AUC score: 0.910802\n",
      "\n",
      "Epoch 00019: ReduceLROnPlateau reducing learning rate to 0.0019000000902451575.\n",
      "Epoch 20/50\n",
      " - 10s - loss: 0.1783 - acc: 0.9342 - val_loss: 0.2050 - val_acc: 0.9260\n",
      "AUC score: 0.911167\n",
      "Epoch 21/50\n",
      " - 10s - loss: 0.1811 - acc: 0.9329 - val_loss: 0.1818 - val_acc: 0.9260\n",
      "AUC score: 0.911861\n",
      "Epoch 22/50\n",
      " - 10s - loss: 0.1796 - acc: 0.9340 - val_loss: 0.2001 - val_acc: 0.9140\n",
      "AUC score: 0.912263\n",
      "Epoch 23/50\n",
      " - 10s - loss: 0.1810 - acc: 0.9330 - val_loss: 0.2034 - val_acc: 0.9230\n",
      "AUC score: 0.912202\n",
      "Epoch 24/50\n",
      " - 10s - loss: 0.1780 - acc: 0.9339 - val_loss: 0.1986 - val_acc: 0.9310\n",
      "AUC score: 0.911274\n",
      "Epoch 25/50\n",
      " - 10s - loss: 0.1768 - acc: 0.9346 - val_loss: 0.2114 - val_acc: 0.9240\n",
      "AUC score: 0.912020\n",
      "Epoch 26/50\n",
      " - 10s - loss: 0.1758 - acc: 0.9348 - val_loss: 0.1858 - val_acc: 0.9280\n",
      "AUC score: 0.911431\n",
      "Epoch 27/50\n",
      " - 10s - loss: 0.1770 - acc: 0.9341 - val_loss: 0.1812 - val_acc: 0.9320\n",
      "AUC score: 0.913299\n",
      "Epoch 28/50\n",
      " - 10s - loss: 0.1758 - acc: 0.9351 - val_loss: 0.1740 - val_acc: 0.9370\n",
      "AUC score: 0.911974\n",
      "Epoch 29/50\n",
      " - 10s - loss: 0.1771 - acc: 0.9340 - val_loss: 0.1961 - val_acc: 0.9300\n",
      "AUC score: 0.912497\n",
      "Epoch 30/50\n",
      " - 10s - loss: 0.1770 - acc: 0.9347 - val_loss: 0.1929 - val_acc: 0.9340\n",
      "AUC score: 0.912005\n",
      "Epoch 31/50\n",
      " - 10s - loss: 0.1755 - acc: 0.9350 - val_loss: 0.1790 - val_acc: 0.9380\n",
      "AUC score: 0.912043\n",
      "Epoch 32/50\n",
      " - 11s - loss: 0.1778 - acc: 0.9336 - val_loss: 0.1841 - val_acc: 0.9260\n",
      "AUC score: 0.911890\n",
      "Epoch 33/50\n",
      " - 10s - loss: 0.1764 - acc: 0.9344 - val_loss: 0.1876 - val_acc: 0.9280\n",
      "AUC score: 0.913220\n",
      "Early stopping: 6\n",
      "Minimum loss for given fold:  0.16054405272006989\n",
      "Fold 2 score: 0.913299\n",
      "Start fold 3\n",
      "Train data: (160000, 802) (160000,)\n",
      "Valid data: (40000, 802) (40000,)\n",
      "Train data: (160000, 800) (160000,)\n",
      "Valid data: (40000, 800) (40000,)\n",
      "Valid sum: 4020\n",
      "Batch size: 1000\n",
      "Learning rate: 0.002\n",
      "Steps train: 160, Steps valid: 1\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_3 (InputLayer)         (None, 800, 1)            0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 800, 1)            3200      \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 800, 128)          256       \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 102400)            0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 1)                 102401    \n",
      "=================================================================\n",
      "Total params: 105,857\n",
      "Trainable params: 104,257\n",
      "Non-trainable params: 1,600\n",
      "_________________________________________________________________\n",
      "None\n",
      "Model memory usage: 0.769 GB\n",
      "Epoch 1/50\n",
      " - 13s - loss: 0.3057 - acc: 0.9042 - val_loss: 0.2569 - val_acc: 0.9050\n",
      "AUC score: 0.877355\n",
      "Epoch 2/50\n",
      " - 10s - loss: 0.2158 - acc: 0.9197 - val_loss: 0.2136 - val_acc: 0.9220\n",
      "AUC score: 0.887657\n",
      "Epoch 3/50\n",
      " - 11s - loss: 0.2093 - acc: 0.9226 - val_loss: 0.2090 - val_acc: 0.9220\n",
      "AUC score: 0.895427\n",
      "Epoch 4/50\n",
      " - 11s - loss: 0.2025 - acc: 0.9257 - val_loss: 0.1794 - val_acc: 0.9360\n",
      "AUC score: 0.899977\n",
      "Epoch 5/50\n",
      " - 11s - loss: 0.1977 - acc: 0.9269 - val_loss: 0.2299 - val_acc: 0.9080\n",
      "AUC score: 0.906276\n",
      "Epoch 6/50\n",
      " - 11s - loss: 0.1924 - acc: 0.9290 - val_loss: 0.2293 - val_acc: 0.9110\n",
      "AUC score: 0.909152\n",
      "Epoch 7/50\n",
      " - 12s - loss: 0.1914 - acc: 0.9288 - val_loss: 0.1747 - val_acc: 0.9390\n",
      "AUC score: 0.911329\n",
      "Epoch 8/50\n",
      " - 11s - loss: 0.1922 - acc: 0.9289 - val_loss: 0.1620 - val_acc: 0.9430\n",
      "AUC score: 0.912100\n",
      "Epoch 9/50\n",
      " - 11s - loss: 0.1875 - acc: 0.9305 - val_loss: 0.1946 - val_acc: 0.9260\n",
      "AUC score: 0.914481\n",
      "Epoch 10/50\n",
      " - 11s - loss: 0.1853 - acc: 0.9316 - val_loss: 0.2040 - val_acc: 0.9240\n",
      "AUC score: 0.914459\n",
      "Epoch 11/50\n",
      " - 11s - loss: 0.1859 - acc: 0.9315 - val_loss: 0.2021 - val_acc: 0.9330\n",
      "AUC score: 0.915558\n",
      "Epoch 12/50\n",
      " - 11s - loss: 0.1831 - acc: 0.9320 - val_loss: 0.1732 - val_acc: 0.9300\n",
      "AUC score: 0.916470\n",
      "Epoch 13/50\n",
      " - 11s - loss: 0.1809 - acc: 0.9333 - val_loss: 0.1683 - val_acc: 0.9400\n",
      "AUC score: 0.915560\n",
      "Epoch 14/50\n",
      " - 11s - loss: 0.1844 - acc: 0.9322 - val_loss: 0.2125 - val_acc: 0.9300\n",
      "AUC score: 0.918683\n",
      "Epoch 15/50\n",
      " - 11s - loss: 0.1842 - acc: 0.9316 - val_loss: 0.2220 - val_acc: 0.9190\n",
      "AUC score: 0.917227\n",
      "Epoch 16/50\n",
      " - 11s - loss: 0.1828 - acc: 0.9320 - val_loss: 0.2232 - val_acc: 0.9200\n",
      "AUC score: 0.917503\n",
      "Epoch 17/50\n",
      " - 11s - loss: 0.1825 - acc: 0.9329 - val_loss: 0.1932 - val_acc: 0.9280\n",
      "AUC score: 0.918175\n",
      "Epoch 18/50\n",
      " - 11s - loss: 0.1804 - acc: 0.9332 - val_loss: 0.2070 - val_acc: 0.9230\n",
      "AUC score: 0.917152\n",
      "Epoch 19/50\n",
      " - 11s - loss: 0.1815 - acc: 0.9331 - val_loss: 0.1893 - val_acc: 0.9320\n",
      "AUC score: 0.918594\n",
      "Epoch 20/50\n",
      " - 11s - loss: 0.1803 - acc: 0.9332 - val_loss: 0.1850 - val_acc: 0.9320\n",
      "AUC score: 0.919460\n",
      "Epoch 21/50\n",
      " - 11s - loss: 0.1804 - acc: 0.9334 - val_loss: 0.1724 - val_acc: 0.9330\n",
      "AUC score: 0.917871\n",
      "Epoch 22/50\n",
      " - 11s - loss: 0.1802 - acc: 0.9329 - val_loss: 0.1923 - val_acc: 0.9280\n",
      "AUC score: 0.918446\n",
      "Epoch 23/50\n",
      " - 11s - loss: 0.1798 - acc: 0.9337 - val_loss: 0.1710 - val_acc: 0.9400\n",
      "AUC score: 0.919435\n",
      "Epoch 24/50\n",
      " - 11s - loss: 0.1792 - acc: 0.9340 - val_loss: 0.1583 - val_acc: 0.9450\n",
      "AUC score: 0.919887\n",
      "Epoch 25/50\n",
      " - 12s - loss: 0.1787 - acc: 0.9338 - val_loss: 0.1908 - val_acc: 0.9320\n",
      "AUC score: 0.919464\n",
      "Epoch 26/50\n",
      " - 11s - loss: 0.1800 - acc: 0.9338 - val_loss: 0.1795 - val_acc: 0.9310\n",
      "AUC score: 0.920220\n",
      "Epoch 27/50\n",
      " - 11s - loss: 0.1782 - acc: 0.9343 - val_loss: 0.1846 - val_acc: 0.9260\n",
      "AUC score: 0.920740\n",
      "Epoch 28/50\n",
      " - 11s - loss: 0.1777 - acc: 0.9339 - val_loss: 0.1679 - val_acc: 0.9430\n",
      "AUC score: 0.919558\n",
      "Epoch 29/50\n",
      " - 11s - loss: 0.1744 - acc: 0.9356 - val_loss: 0.1906 - val_acc: 0.9270\n",
      "AUC score: 0.920465\n",
      "Epoch 30/50\n",
      " - 11s - loss: 0.1794 - acc: 0.9336 - val_loss: 0.1938 - val_acc: 0.9330\n",
      "AUC score: 0.920182\n",
      "Epoch 31/50\n",
      " - 11s - loss: 0.1755 - acc: 0.9355 - val_loss: 0.1828 - val_acc: 0.9270\n",
      "AUC score: 0.920399\n",
      "Epoch 32/50\n",
      " - 11s - loss: 0.1746 - acc: 0.9357 - val_loss: 0.1888 - val_acc: 0.9310\n",
      "AUC score: 0.919527\n",
      "Epoch 33/50\n",
      " - 11s - loss: 0.1760 - acc: 0.9349 - val_loss: 0.1911 - val_acc: 0.9330\n",
      "AUC score: 0.919592\n",
      "Early stopping: 6\n",
      "Minimum loss for given fold:  0.15825191140174866\n",
      "Fold 3 score: 0.920740\n",
      "Start fold 4\n",
      "Train data: (160001, 802) (160001,)\n",
      "Valid data: (39999, 802) (39999,)\n",
      "Train data: (160001, 800) (160001,)\n",
      "Valid data: (39999, 800) (39999,)\n",
      "Valid sum: 4019\n",
      "Batch size: 1000\n",
      "Learning rate: 0.002\n",
      "Steps train: 160, Steps valid: 1\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         (None, 800, 1)            0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 800, 1)            3200      \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 800, 128)          256       \n",
      "_________________________________________________________________\n",
      "flatten_4 (Flatten)          (None, 102400)            0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 1)                 102401    \n",
      "=================================================================\n",
      "Total params: 105,857\n",
      "Trainable params: 104,257\n",
      "Non-trainable params: 1,600\n",
      "_________________________________________________________________\n",
      "None\n",
      "Model memory usage: 0.769 GB\n",
      "Epoch 1/50\n",
      " - 14s - loss: 0.3024 - acc: 0.9039 - val_loss: 0.2298 - val_acc: 0.9200\n",
      "AUC score: 0.875465\n",
      "Epoch 2/50\n",
      " - 11s - loss: 0.2138 - acc: 0.9208 - val_loss: 0.2027 - val_acc: 0.9230\n",
      "AUC score: 0.882586\n",
      "Epoch 3/50\n",
      " - 11s - loss: 0.2056 - acc: 0.9233 - val_loss: 0.2239 - val_acc: 0.9200\n",
      "AUC score: 0.890213\n",
      "Epoch 4/50\n",
      " - 11s - loss: 0.2024 - acc: 0.9251 - val_loss: 0.2293 - val_acc: 0.9170\n",
      "AUC score: 0.897484\n",
      "Epoch 5/50\n",
      " - 12s - loss: 0.1953 - acc: 0.9277 - val_loss: 0.2053 - val_acc: 0.9310\n",
      "AUC score: 0.902362\n",
      "Epoch 6/50\n",
      " - 12s - loss: 0.1936 - acc: 0.9282 - val_loss: 0.1958 - val_acc: 0.9290\n",
      "AUC score: 0.907078\n",
      "Epoch 7/50\n",
      " - 12s - loss: 0.1884 - acc: 0.9304 - val_loss: 0.2117 - val_acc: 0.9240\n",
      "AUC score: 0.907126\n",
      "Epoch 8/50\n",
      " - 12s - loss: 0.1876 - acc: 0.9302 - val_loss: 0.2316 - val_acc: 0.9160\n",
      "AUC score: 0.909631\n",
      "Epoch 9/50\n",
      " - 11s - loss: 0.1886 - acc: 0.9301 - val_loss: 0.2316 - val_acc: 0.9150\n",
      "AUC score: 0.909513\n",
      "Epoch 10/50\n",
      " - 11s - loss: 0.1849 - acc: 0.9321 - val_loss: 0.1851 - val_acc: 0.9350\n",
      "AUC score: 0.912020\n",
      "Epoch 11/50\n",
      " - 11s - loss: 0.1826 - acc: 0.9325 - val_loss: 0.1914 - val_acc: 0.9280\n",
      "AUC score: 0.912335\n",
      "Epoch 12/50\n",
      " - 12s - loss: 0.1831 - acc: 0.9323 - val_loss: 0.1801 - val_acc: 0.9330\n",
      "AUC score: 0.912765\n",
      "Epoch 13/50\n",
      " - 12s - loss: 0.1831 - acc: 0.9311 - val_loss: 0.1777 - val_acc: 0.9270\n",
      "AUC score: 0.913412\n",
      "Epoch 14/50\n",
      " - 12s - loss: 0.1804 - acc: 0.9333 - val_loss: 0.2318 - val_acc: 0.9070\n",
      "AUC score: 0.912651\n",
      "Epoch 15/50\n",
      " - 12s - loss: 0.1809 - acc: 0.9331 - val_loss: 0.1970 - val_acc: 0.9320\n",
      "AUC score: 0.915205\n",
      "Epoch 16/50\n",
      " - 13s - loss: 0.1827 - acc: 0.9326 - val_loss: 0.1723 - val_acc: 0.9340\n",
      "AUC score: 0.913882\n",
      "Epoch 17/50\n",
      " - 11s - loss: 0.1798 - acc: 0.9337 - val_loss: 0.1944 - val_acc: 0.9240\n",
      "AUC score: 0.914381\n",
      "Epoch 18/50\n",
      " - 11s - loss: 0.1809 - acc: 0.9332 - val_loss: 0.1574 - val_acc: 0.9420\n",
      "AUC score: 0.916168\n",
      "Epoch 19/50\n",
      " - 12s - loss: 0.1788 - acc: 0.9340 - val_loss: 0.2236 - val_acc: 0.9190\n",
      "AUC score: 0.915119\n",
      "Epoch 20/50\n",
      " - 12s - loss: 0.1783 - acc: 0.9342 - val_loss: 0.1995 - val_acc: 0.9300\n",
      "AUC score: 0.914777\n",
      "Epoch 21/50\n",
      " - 11s - loss: 0.1798 - acc: 0.9333 - val_loss: 0.2157 - val_acc: 0.9160\n",
      "AUC score: 0.915050\n",
      "Epoch 22/50\n",
      " - 11s - loss: 0.1771 - acc: 0.9345 - val_loss: 0.2153 - val_acc: 0.9160\n",
      "AUC score: 0.915544\n",
      "Epoch 23/50\n",
      " - 12s - loss: 0.1750 - acc: 0.9351 - val_loss: 0.1915 - val_acc: 0.9210\n",
      "AUC score: 0.916436\n",
      "Epoch 24/50\n",
      " - 12s - loss: 0.1786 - acc: 0.9341 - val_loss: 0.1837 - val_acc: 0.9280\n",
      "AUC score: 0.916660\n",
      "Epoch 25/50\n",
      " - 11s - loss: 0.1792 - acc: 0.9344 - val_loss: 0.2146 - val_acc: 0.9270\n",
      "AUC score: 0.916825\n",
      "Epoch 26/50\n",
      " - 12s - loss: 0.1751 - acc: 0.9354 - val_loss: 0.1677 - val_acc: 0.9450\n",
      "AUC score: 0.917155\n",
      "Epoch 27/50\n",
      " - 11s - loss: 0.1775 - acc: 0.9349 - val_loss: 0.2040 - val_acc: 0.9160\n",
      "AUC score: 0.917700\n",
      "Epoch 28/50\n",
      " - 12s - loss: 0.1776 - acc: 0.9341 - val_loss: 0.1802 - val_acc: 0.9280\n",
      "AUC score: 0.915739\n",
      "\n",
      "Epoch 00028: ReduceLROnPlateau reducing learning rate to 0.0019000000902451575.\n",
      "Epoch 29/50\n",
      " - 11s - loss: 0.1789 - acc: 0.9343 - val_loss: 0.1681 - val_acc: 0.9370\n",
      "AUC score: 0.918188\n",
      "Epoch 30/50\n",
      " - 12s - loss: 0.1785 - acc: 0.9347 - val_loss: 0.1912 - val_acc: 0.9280\n",
      "AUC score: 0.916636\n",
      "Epoch 31/50\n",
      " - 11s - loss: 0.1780 - acc: 0.9345 - val_loss: 0.1899 - val_acc: 0.9240\n",
      "AUC score: 0.917283\n",
      "Epoch 32/50\n",
      " - 12s - loss: 0.1768 - acc: 0.9349 - val_loss: 0.2092 - val_acc: 0.9250\n",
      "AUC score: 0.917937\n",
      "Epoch 33/50\n",
      " - 12s - loss: 0.1747 - acc: 0.9351 - val_loss: 0.1894 - val_acc: 0.9330\n",
      "AUC score: 0.918122\n",
      "Epoch 34/50\n",
      " - 12s - loss: 0.1787 - acc: 0.9332 - val_loss: 0.1936 - val_acc: 0.9280\n",
      "AUC score: 0.917952\n",
      "Epoch 35/50\n",
      " - 12s - loss: 0.1764 - acc: 0.9348 - val_loss: 0.1915 - val_acc: 0.9310\n",
      "AUC score: 0.918396\n",
      "Epoch 36/50\n",
      " - 11s - loss: 0.1780 - acc: 0.9342 - val_loss: 0.1921 - val_acc: 0.9190\n",
      "AUC score: 0.917920\n",
      "Epoch 37/50\n",
      " - 12s - loss: 0.1750 - acc: 0.9359 - val_loss: 0.2113 - val_acc: 0.9300\n",
      "AUC score: 0.919234\n",
      "Epoch 38/50\n",
      " - 12s - loss: 0.1756 - acc: 0.9347 - val_loss: 0.1891 - val_acc: 0.9260\n",
      "AUC score: 0.918000\n",
      "\n",
      "Epoch 00038: ReduceLROnPlateau reducing learning rate to 0.0018050000304356217.\n",
      "Epoch 39/50\n",
      " - 12s - loss: 0.1735 - acc: 0.9359 - val_loss: 0.2053 - val_acc: 0.9270\n",
      "AUC score: 0.917248\n",
      "Epoch 40/50\n",
      " - 12s - loss: 0.1747 - acc: 0.9360 - val_loss: 0.1664 - val_acc: 0.9320\n",
      "AUC score: 0.918365\n",
      "Epoch 41/50\n",
      " - 13s - loss: 0.1713 - acc: 0.9368 - val_loss: 0.1769 - val_acc: 0.9320\n",
      "AUC score: 0.918479\n",
      "Epoch 42/50\n",
      " - 11s - loss: 0.1756 - acc: 0.9354 - val_loss: 0.1867 - val_acc: 0.9250\n",
      "AUC score: 0.917802\n",
      "Epoch 43/50\n",
      " - 11s - loss: 0.1719 - acc: 0.9365 - val_loss: 0.1786 - val_acc: 0.9350\n",
      "AUC score: 0.917282\n",
      "Early stopping: 6\n",
      "Minimum loss for given fold:  0.15743570029735565\n",
      "Fold 4 score: 0.919234\n",
      "Start fold 5\n",
      "Train data: (160001, 802) (160001,)\n",
      "Valid data: (39999, 802) (39999,)\n",
      "Train data: (160001, 800) (160001,)\n",
      "Valid data: (39999, 800) (39999,)\n",
      "Valid sum: 4019\n",
      "Batch size: 1000\n",
      "Learning rate: 0.002\n",
      "Steps train: 160, Steps valid: 1\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_5 (InputLayer)         (None, 800, 1)            0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 800, 1)            3200      \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 800, 128)          256       \n",
      "_________________________________________________________________\n",
      "flatten_5 (Flatten)          (None, 102400)            0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 1)                 102401    \n",
      "=================================================================\n",
      "Total params: 105,857\n",
      "Trainable params: 104,257\n",
      "Non-trainable params: 1,600\n",
      "_________________________________________________________________\n",
      "None\n",
      "Model memory usage: 0.769 GB\n",
      "Epoch 1/50\n",
      " - 12s - loss: 0.3396 - acc: 0.8986 - val_loss: 0.2055 - val_acc: 0.9160\n",
      "AUC score: 0.873084\n",
      "Epoch 2/50\n",
      " - 10s - loss: 0.2168 - acc: 0.9197 - val_loss: 0.2577 - val_acc: 0.8980\n",
      "AUC score: 0.881690\n",
      "Epoch 3/50\n",
      " - 10s - loss: 0.2085 - acc: 0.9227 - val_loss: 0.2277 - val_acc: 0.9190\n",
      "AUC score: 0.888971\n",
      "Epoch 4/50\n",
      " - 10s - loss: 0.2050 - acc: 0.9240 - val_loss: 0.1864 - val_acc: 0.9330\n",
      "AUC score: 0.896168\n",
      "Epoch 5/50\n",
      " - 10s - loss: 0.1980 - acc: 0.9260 - val_loss: 0.1846 - val_acc: 0.9360\n",
      "AUC score: 0.900893\n",
      "Epoch 6/50\n",
      " - 10s - loss: 0.1947 - acc: 0.9271 - val_loss: 0.1617 - val_acc: 0.9430\n",
      "AUC score: 0.904884\n",
      "Epoch 7/50\n",
      " - 10s - loss: 0.1888 - acc: 0.9302 - val_loss: 0.1885 - val_acc: 0.9290\n",
      "AUC score: 0.907547\n",
      "Epoch 8/50\n",
      " - 10s - loss: 0.1906 - acc: 0.9295 - val_loss: 0.1881 - val_acc: 0.9290\n",
      "AUC score: 0.907625\n",
      "Epoch 9/50\n",
      " - 11s - loss: 0.1865 - acc: 0.9310 - val_loss: 0.1782 - val_acc: 0.9350\n",
      "AUC score: 0.910000\n",
      "Epoch 10/50\n",
      " - 10s - loss: 0.1860 - acc: 0.9311 - val_loss: 0.1863 - val_acc: 0.9280\n",
      "AUC score: 0.910342\n",
      "Epoch 11/50\n",
      " - 10s - loss: 0.1861 - acc: 0.9310 - val_loss: 0.1795 - val_acc: 0.9340\n",
      "AUC score: 0.911392\n",
      "Epoch 12/50\n",
      " - 10s - loss: 0.1862 - acc: 0.9310 - val_loss: 0.1861 - val_acc: 0.9310\n",
      "AUC score: 0.911799\n",
      "Epoch 13/50\n",
      " - 9s - loss: 0.1830 - acc: 0.9326 - val_loss: 0.1799 - val_acc: 0.9290\n",
      "AUC score: 0.911169\n",
      "Epoch 14/50\n",
      " - 9s - loss: 0.1839 - acc: 0.9320 - val_loss: 0.1845 - val_acc: 0.9330\n",
      "AUC score: 0.912564\n",
      "Epoch 15/50\n",
      " - 9s - loss: 0.1854 - acc: 0.9318 - val_loss: 0.1825 - val_acc: 0.9350\n",
      "AUC score: 0.912947\n",
      "Epoch 16/50\n",
      " - 10s - loss: 0.1799 - acc: 0.9333 - val_loss: 0.1932 - val_acc: 0.9340\n",
      "AUC score: 0.912761\n",
      "Epoch 17/50\n",
      " - 10s - loss: 0.1789 - acc: 0.9341 - val_loss: 0.1946 - val_acc: 0.9250\n",
      "AUC score: 0.913348\n",
      "Epoch 18/50\n",
      " - 10s - loss: 0.1812 - acc: 0.9328 - val_loss: 0.2165 - val_acc: 0.9190\n",
      "AUC score: 0.913875\n",
      "Epoch 19/50\n",
      " - 9s - loss: 0.1825 - acc: 0.9327 - val_loss: 0.1798 - val_acc: 0.9260\n",
      "AUC score: 0.914386\n",
      "Epoch 20/50\n",
      " - 10s - loss: 0.1789 - acc: 0.9333 - val_loss: 0.1750 - val_acc: 0.9310\n",
      "AUC score: 0.914554\n",
      "Epoch 21/50\n",
      " - 10s - loss: 0.1783 - acc: 0.9339 - val_loss: 0.1837 - val_acc: 0.9290\n",
      "AUC score: 0.913060\n",
      "Epoch 22/50\n",
      " - 10s - loss: 0.1769 - acc: 0.9345 - val_loss: 0.2175 - val_acc: 0.9220\n",
      "AUC score: 0.915034\n",
      "Epoch 23/50\n",
      " - 9s - loss: 0.1808 - acc: 0.9336 - val_loss: 0.1920 - val_acc: 0.9310\n",
      "AUC score: 0.914573\n",
      "Epoch 24/50\n",
      " - 10s - loss: 0.1804 - acc: 0.9329 - val_loss: 0.1869 - val_acc: 0.9390\n",
      "AUC score: 0.915637\n",
      "Epoch 25/50\n",
      " - 10s - loss: 0.1783 - acc: 0.9344 - val_loss: 0.1807 - val_acc: 0.9330\n",
      "AUC score: 0.915597\n",
      "Epoch 26/50\n",
      " - 10s - loss: 0.1772 - acc: 0.9345 - val_loss: 0.1758 - val_acc: 0.9340\n",
      "AUC score: 0.914878\n",
      "Epoch 27/50\n",
      " - 9s - loss: 0.1778 - acc: 0.9345 - val_loss: 0.1749 - val_acc: 0.9400\n",
      "AUC score: 0.915111\n",
      "\n",
      "Epoch 00027: ReduceLROnPlateau reducing learning rate to 0.0019000000902451575.\n",
      "Epoch 28/50\n",
      " - 9s - loss: 0.1767 - acc: 0.9352 - val_loss: 0.1949 - val_acc: 0.9290\n",
      "AUC score: 0.915298\n",
      "Epoch 29/50\n",
      " - 9s - loss: 0.1798 - acc: 0.9333 - val_loss: 0.1878 - val_acc: 0.9280\n",
      "AUC score: 0.915202\n",
      "Epoch 30/50\n",
      " - 10s - loss: 0.1774 - acc: 0.9348 - val_loss: 0.1869 - val_acc: 0.9270\n",
      "AUC score: 0.915004\n",
      "Early stopping: 6\n",
      "Minimum loss for given fold:  0.16170811653137207\n",
      "Fold 5 score: 0.915637\n",
      "Total AUC score: 0.917321\n"
     ]
    }
   ],
   "source": [
    "def get_keras_model(input_features):\n",
    "    from keras.models import Model\n",
    "    from keras.layers import Input, Dense, BatchNormalization, Conv1D, Reshape, Flatten, MaxPooling1D, Concatenate\n",
    "    from keras.layers.core import Activation, Dropout, Lambda\n",
    "    from keras.layers.merge import concatenate\n",
    "\n",
    "    inp = Input(shape=(input_features, 1))\n",
    "    x = BatchNormalization(axis=-2)(inp)\n",
    "    x = Dense(128, activation='relu')(x)\n",
    "    x = Flatten()(x)\n",
    "    preds = Dense(1, activation='sigmoid')(x)\n",
    "    model = Model(inputs=inp, outputs=preds)\n",
    "    return model\n",
    "\n",
    "\n",
    "def get_kfold_split(folds_number, len_train, target, random_state):\n",
    "    train_index = list(range(len_train))\n",
    "    folds = StratifiedKFold(n_splits=folds_number, shuffle=True, random_state=random_state)\n",
    "    ret = []\n",
    "    for n_fold, (trn_idx, val_idx) in enumerate(folds.split(train_index, target)):\n",
    "        ret.append([trn_idx, val_idx])\n",
    "    return ret\n",
    "\n",
    "\n",
    "def get_model_memory_usage(batch_size, model):\n",
    "    import numpy as np\n",
    "    from keras import backend as K\n",
    "\n",
    "    shapes_mem_count = 0\n",
    "    for l in model.layers:\n",
    "        single_layer_mem = 1\n",
    "        for s in l.output_shape:\n",
    "            if s is None:\n",
    "                continue\n",
    "            single_layer_mem *= s\n",
    "        shapes_mem_count += single_layer_mem\n",
    "\n",
    "    trainable_count = np.sum([K.count_params(p) for p in set(model.trainable_weights)])\n",
    "    non_trainable_count = np.sum([K.count_params(p) for p in set(model.non_trainable_weights)])\n",
    "\n",
    "    number_size = 4.0\n",
    "    if K.floatx() == 'float16':\n",
    "         number_size = 2.0\n",
    "    if K.floatx() == 'float64':\n",
    "         number_size = 8.0\n",
    "\n",
    "    total_memory = number_size*(batch_size*shapes_mem_count + trainable_count + non_trainable_count)\n",
    "    gbytes = np.round(total_memory / (1024.0 ** 3), 3)\n",
    "    return gbytes\n",
    "\n",
    "\n",
    "class ModelCheckpoint_AUC(Callback):\n",
    "    \"\"\"Save the model after every epoch. \"\"\"\n",
    "\n",
    "    def __init__(self, filepath, filepath_static, monitor='val_loss', verbose=0,\n",
    "                 save_best_only=False, save_weights_only=False,\n",
    "                 mode='max', period=1, patience=None, validation_data=()):\n",
    "        super(ModelCheckpoint_AUC, self).__init__()\n",
    "        self.interval = period\n",
    "        self.X_val, self.y_val, self.batch_size = validation_data\n",
    "        self.monitor = monitor\n",
    "        self.verbose = verbose\n",
    "        self.filepath = filepath\n",
    "        self.filepath_static = filepath_static\n",
    "        self.save_best_only = save_best_only\n",
    "        self.save_weights_only = save_weights_only\n",
    "        self.period = period\n",
    "        self.epochs_since_last_save = 0\n",
    "        self.monitor_op = np.greater\n",
    "        self.best = -np.Inf\n",
    "\n",
    "        # part for early stopping\n",
    "        self.epochs_from_best_model = 0\n",
    "        self.patience = patience\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        logs = logs or {}\n",
    "        self.epochs_since_last_save += 1\n",
    "        if self.epochs_since_last_save >= self.period:\n",
    "            self.epochs_since_last_save = 0\n",
    "\n",
    "            y_pred = self.model.predict(self.X_val, verbose=0, batch_size=self.batch_size)\n",
    "            score = roc_auc_score(self.y_val, y_pred)\n",
    "            filepath = self.filepath.format(epoch=epoch + 1, score=score, **logs)\n",
    "            print(\"AUC score: {:.6f}\".format(score))\n",
    "            if score > self.best:\n",
    "                self.epochs_from_best_model = 0\n",
    "            else:\n",
    "                self.epochs_from_best_model += 1\n",
    "\n",
    "            if self.save_best_only:\n",
    "                current = score\n",
    "                if current is None:\n",
    "                    warnings.warn('Can save best model only with %s available, '\n",
    "                                  'skipping.' % (self.monitor), RuntimeWarning)\n",
    "                else:\n",
    "                    if self.monitor_op(current, self.best):\n",
    "                        if self.verbose > 0:\n",
    "                            print('\\nEpoch %05d: %s improved from %0.5f to %0.5f,'\n",
    "                                  ' saving model to %s'\n",
    "                                  % (epoch + 1, self.monitor, self.best,\n",
    "                                     current, filepath))\n",
    "                        self.best = current\n",
    "                        if self.save_weights_only:\n",
    "                            self.model.save_weights(filepath, overwrite=True)\n",
    "                        else:\n",
    "                            self.model.save(filepath, overwrite=True)\n",
    "                        shutil.copy(filepath, self.filepath_static)\n",
    "                    else:\n",
    "                        if self.verbose > 0:\n",
    "                            print('\\nEpoch %05d: %s did not improve' %\n",
    "                                  (epoch + 1, self.monitor))\n",
    "            else:\n",
    "                if self.verbose > 0:\n",
    "                    print('\\nEpoch %05d: saving model to %s' % (epoch + 1, filepath))\n",
    "                if self.save_weights_only:\n",
    "                    self.model.save_weights(filepath, overwrite=True)\n",
    "                else:\n",
    "                    self.model.save(filepath, overwrite=True)\n",
    "                shutil.copy(filepath, self.filepath_static)\n",
    "\n",
    "            if self.patience is not None:\n",
    "                if self.epochs_from_best_model > self.patience:\n",
    "                    print('Early stopping: {}'.format(self.epochs_from_best_model))\n",
    "                    self.model.stop_training = True\n",
    "\n",
    "\n",
    "def batch_generator_train_random_sample(X, y, batch_size):\n",
    "    rng = list(range(X.shape[0]))\n",
    "    feature_group_number = 4\n",
    "\n",
    "    while True:\n",
    "        index1 = random.sample(rng, batch_size)\n",
    "        input1 = X[index1, :].copy()\n",
    "        output1 = y[index1].copy()\n",
    "\n",
    "        input1_0 = input1[output1 == 0, :]\n",
    "        input1_1 = input1[output1 == 1, :]\n",
    "        output1_0 = output1[output1 == 0]\n",
    "        output1_1 = output1[output1 == 1]\n",
    "\n",
    "        for i in range(0, input1.shape[1], feature_group_number):\n",
    "            index = np.arange(0, input1_0.shape[0])\n",
    "            np.random.shuffle(index)\n",
    "            for j in range(feature_group_number):\n",
    "                input1_0[:, i + j] = input1_0[index, i + j]\n",
    "\n",
    "            index = np.arange(0, input1_1.shape[0])\n",
    "            np.random.shuffle(index)\n",
    "            for j in range(feature_group_number):\n",
    "                input1_1[:, i + j] = input1_1[index, i + j]\n",
    "\n",
    "        input1 = np.concatenate((input1_0, input1_1), axis=0)\n",
    "        output1 = np.concatenate((output1_0, output1_1), axis=0)\n",
    "        input1 = np.expand_dims(input1, axis=2)\n",
    "        yield input1, output1\n",
    "                    \n",
    "\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "target = train['target'].values\n",
    "overall_train_predictions = np.zeros(target.shape[0], dtype=np.float64)\n",
    "model_list = []\n",
    "all_splits = []\n",
    "num_fold = 0\n",
    "ret = get_kfold_split(5, train.shape[0], target, 890)\n",
    "\n",
    "for train_index, valid_index in ret:\n",
    "    num_fold += 1\n",
    "    print('Start fold {}'.format(num_fold))\n",
    "    X_train = train.loc[train_index].copy()\n",
    "    X_valid = train.loc[valid_index].copy()\n",
    "    y_train = target[train_index]\n",
    "    y_valid = target[valid_index]\n",
    "\n",
    "    print('Train data:', X_train.shape, y_train.shape)\n",
    "    print('Valid data:', X_valid.shape, y_valid.shape)\n",
    "\n",
    "    X_train_matrix = X_train[features].values\n",
    "    X_valid_matrix = X_valid[features].values\n",
    "\n",
    "    print('Train data:', X_train_matrix.shape, y_train.shape)\n",
    "    print('Valid data:', X_valid_matrix.shape, y_valid.shape)\n",
    "    print('Valid sum: {}'.format(y_valid.sum()))\n",
    "\n",
    "    optim_name = 'Adam'\n",
    "    batch_size_train = 1000\n",
    "    batch_size_valid = 1000\n",
    "    learning_rate = 0.002\n",
    "    epochs = 50\n",
    "    patience = 5\n",
    "    print('Batch size: {}'.format(batch_size_train))\n",
    "    print('Learning rate: {}'.format(learning_rate))\n",
    "    steps_per_epoch = (X_train.shape[0] // batch_size_train)\n",
    "    validation_steps = 1\n",
    "    print('Steps train: {}, Steps valid: {}'.format(steps_per_epoch, validation_steps))\n",
    "\n",
    "    final_model_path = MODELS_PATH_KERAS + '{}_fold_{}.h5'.format('keras', num_fold)\n",
    "    cache_model_path = MODELS_PATH_KERAS + '{}_temp_fold_{}.h5'.format('keras', num_fold)\n",
    "    cache_model_path_auc = MODELS_PATH_KERAS + '{}_temp_fold_{}'.format('keras', num_fold) + '_{score:.4f}.h5'\n",
    "\n",
    "    model = get_keras_model(X_train_matrix.shape[1])\n",
    "    print(model.summary())\n",
    "    print('Model memory usage: {} GB'.format(get_model_memory_usage(batch_size_train, model)))\n",
    "\n",
    "    optim = Adam(lr=learning_rate)\n",
    "    model.compile(optimizer=optim, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    callbacks = [\n",
    "        # EarlyStopping(monitor='val_loss', patience=patience, verbose=0),\n",
    "        ModelCheckpoint_AUC(cache_model_path_auc, cache_model_path,\n",
    "                            validation_data=(np.expand_dims(X_valid_matrix, axis=2), y_valid, batch_size_valid),\n",
    "                            save_best_only=True,\n",
    "                            verbose=0,\n",
    "                            patience=patience),\n",
    "        # ModelCheckpoint(cache_model_path, save_best_only=False)\n",
    "        ReduceLROnPlateau(monitor='loss', factor=0.95, patience=5, min_lr=1e-9, min_delta=0.00001,\n",
    "                          verbose=1, mode='min'),\n",
    "    ]\n",
    "\n",
    "    history = model.fit_generator(generator=batch_generator_train_random_sample(X_train_matrix, y_train, batch_size_train),\n",
    "                                  epochs=epochs,\n",
    "                                  steps_per_epoch=steps_per_epoch,\n",
    "                                  validation_data=batch_generator_train_random_sample(X_valid_matrix, y_valid, batch_size_valid),\n",
    "                                  validation_steps=validation_steps,\n",
    "                                  verbose=2,\n",
    "                                  max_queue_size=10,\n",
    "                                  # class_weight=class_weight,\n",
    "                                  callbacks=callbacks)\n",
    "\n",
    "    min_loss = min(history.history['val_loss'])\n",
    "    print('Minimum loss for given fold: ', min_loss)\n",
    "    model.load_weights(cache_model_path)\n",
    "    model.save(final_model_path)\n",
    "\n",
    "    pred = model.predict(np.expand_dims(X_valid[features].values, axis=2))\n",
    "    overall_train_predictions[valid_index] += pred[:, 0]\n",
    "    score = roc_auc_score(y_valid, pred[:, 0])\n",
    "    print('Fold {} score: {:.6f}'.format(num_fold, score))\n",
    "    model_list.append(model)\n",
    "    all_splits.append(ret)\n",
    "\n",
    "score = roc_auc_score(target, overall_train_predictions)\n",
    "print('Total AUC score: {:.6f}'.format(score))\n",
    "\n",
    "train['target'] = overall_train_predictions\n",
    "train[['ID_code', 'target']].to_csv(SUBM_PATH + 'train_auc_{}.csv'.format(score), index=False, float_format='%.8f')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**6) Predict on test**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_with_keras_model(test, features, model_list):\n",
    "    full_preds = []\n",
    "    for m in model_list:\n",
    "        preds = m.predict(np.expand_dims(test[features].values, axis=2), batch_size=1000)\n",
    "        full_preds.append(preds)\n",
    "    preds = np.array(full_preds).mean(axis=0)\n",
    "    return preds\n",
    "\n",
    "overall_test_predictions = predict_with_keras_model(test, features, model_list)\n",
    "test['target'] = overall_test_predictions\n",
    "test[['ID_code', 'target']].to_csv(SUBM_PATH + 'test_auc_{}.csv'.format(score), index=False, float_format='%.8f')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
