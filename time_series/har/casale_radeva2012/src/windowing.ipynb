{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "windowing.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rSHouuIayWOn",
        "colab_type": "text"
      },
      "source": [
        "> # Time windowing experiment"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JdSk2pE3EAqV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## initial setup for google drive and colab\n",
        "import glob\n",
        "import importlib\n",
        "from google.colab import drive\n",
        "drive.mount(\"/content/gdrive\", force_remount=True)\n",
        "import os\n",
        "pathtodata = '/content/gdrive/My Drive/Activity Recognition from Single Chest-Mounted Accelerometer/'\n",
        "os.chdir(pathtodata)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "4NvP3ta3ypN4",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os, sys\n",
        "\n",
        "# number of observation per second based on dataset documentation\n",
        "sample_rate = 52  \n",
        "\n",
        "# number of skipped datapoints to start next window\n",
        "sliding_size = int(.2 * sample_rate)  \n",
        "\n",
        "def mean_crossing_rate(col):\n",
        "    # col = np.array(values)\n",
        "    normalized = col - col.mean()  # to make elements of array possitive or negetive\n",
        "    return ((normalized[:-1] * col[1:]) < 0).sum()  # Zero-Crossing_rate\n",
        "#################################################################\n",
        "\n",
        "\n",
        "def FS1(window): \n",
        "  # only mean\n",
        "\n",
        "    avgs = list(window.mean()[:-1])\n",
        "    ## select the most frequent label as the label of the window\n",
        "    label = window.iloc[:, -1].mode()[0]  \n",
        "    avgs.append(label)\n",
        "    return avgs\n",
        "#################################################################\n",
        "\n",
        "\n",
        "def FS2(window):  \n",
        "  # Mean and std\n",
        "\n",
        "    features = []\n",
        "    features.append(np.array(window.mean()[:-1]))\n",
        "    features.append(np.array(window.std()[:-1]))\n",
        "    features = np.hstack(features).tolist()\n",
        "\n",
        "    label = window.iloc[:, -1].mode()[0] ## select the most frequent label as the label of the window\n",
        "\n",
        "    features.append(label)\n",
        "\n",
        "    return features\n",
        "#################################################################\n",
        "\n",
        "\n",
        "def FS3(window):  \n",
        "  # mean, std,max,min and zero-crossing-rate\n",
        "\n",
        "    features = []\n",
        "    features.append(np.array(window.mean()[:-1]))\n",
        "    features.append(np.array(window.std()[:-1]))\n",
        "    features.append(np.array(window.min()[:-1]))\n",
        "    features.append(np.array(window.max()[:-1]))\n",
        "    mean_crossing = [mean_crossing_rate(window.iloc[:, i].values) for i in range(window.shape[1] - 1)]\n",
        "    features.append(np.array(mean_crossing))\n",
        "\n",
        "    features = np.hstack(features).tolist()\n",
        "\n",
        "    label = window.iloc[:, -1].mode()[0]  ## select the most frequent label as the label of the window\n",
        "    features.append(label)\n",
        "    return features\n",
        "#################################################################\n",
        "\n",
        "\n",
        "def windowing_dataset(dataset, win_size, feature_extraction_function, subject_id, overlap=False):\n",
        "    windowed_dataset = []\n",
        "    win_count = 0\n",
        "    if overlap:\n",
        "        step_size = sliding_size  # for Overlapping technique\n",
        "    else:\n",
        "        step_size = win_size  # for Non-overlapping technique\n",
        "\n",
        "    for index in range(0, dataset.shape[0], step_size):\n",
        "\n",
        "        start = index\n",
        "        end = start + win_size\n",
        "\n",
        "        if (end <= dataset.shape[0]):  # to assure all of windows are equal in size\n",
        "            window = dataset.iloc[start:end, :].reset_index(drop=True)\n",
        "            win_count = win_count + 1\n",
        "            features = feature_extraction_function(window)\n",
        "\n",
        "            windowed_dataset.append(features)\n",
        "\n",
        "    final = pd.DataFrame(windowed_dataset)\n",
        "    final.insert(0, 'group', subject_id)  # to use in Subject CV\n",
        "    return final\n",
        "#################################################################\n",
        "\n",
        "\n",
        "def Preprocessing(dataset_path, output_path, overlapping):\n",
        "\n",
        "    features_functions = [FS1, FS2, FS3]\n",
        "    win_sizes = np.linspace(.25, 3, 12, endpoint=True)\n",
        "    for win_size in win_sizes:\n",
        "\n",
        "        print(\"Start for win size {}\".format(win_size))\n",
        "        datapoints_per_window = int(win_size * sample_rate)\n",
        "\n",
        "        for feature_function in features_functions:\n",
        "\n",
        "            print(feature_function.__name__)\n",
        "\n",
        "            windowed_dataset = []\n",
        "\n",
        "            for subject in range(1, 16):\n",
        "                file_path = dataset_path + \"{}.csv\".format(subject)\n",
        "                #file_path = dataset_path + '/subject{0}_ideal.log'.format(subject)\n",
        "                acc_cols = []\n",
        "                for i in range(2, 117, 13):  # indices of accelarations\n",
        "                    indices = list(range(i, i + 3))\n",
        "                    acc_cols.extend(indices)\n",
        "\n",
        "                acc_cols.append(119)  # label index\n",
        "\n",
        "                tmp_db = pd.read_csv(file_path, header=1)#, usecols=acc_cols, sep='\\t')\n",
        "                tmp_db.columns = list(range(tmp_db.shape[1]))  # re-index the columns\n",
        "\n",
        "                transformed_db = windowing_dataset(tmp_db, datapoints_per_window, feature_function, subject,\n",
        "                                                   overlap=overlapping)\n",
        "\n",
        "                windowed_dataset.append(transformed_db)\n",
        "\n",
        "            final_dataset = pd.DataFrame()\n",
        "            print(\"Merging!\")\n",
        "            final_dataset = final_dataset.append(windowed_dataset, ignore_index=True)\n",
        "\n",
        "            if overlapping:\n",
        "                out_folder_name = 'Overlapping_windowed'\n",
        "            else:\n",
        "                out_folder_name = 'Non-overlapping_windowed'\n",
        "\n",
        "            os.makedirs('{}/{}'.format(output_path, out_folder_name), exist_ok=True)\n",
        "\n",
        "            os.makedirs('{}/{}/FS1'.format(output_path, out_folder_name), exist_ok=True)\n",
        "            os.makedirs('{}/{}/FS2'.format(output_path, out_folder_name), exist_ok=True)\n",
        "            os.makedirs('{}/{}/FS3'.format(output_path, out_folder_name), exist_ok=True)\n",
        "\n",
        "            if (feature_function == FS1):\n",
        "                final_dataset.to_csv('{}/{}/FS1/dataset{}.csv'.format(output_path, out_folder_name, win_size), sep='\\t',\n",
        "                                     index=False)\n",
        "            elif (feature_function == FS2):\n",
        "                final_dataset.to_csv('{}/{}/FS2/dataset{}.csv'.format(output_path, out_folder_name, win_size), sep='\\t',\n",
        "                                     index=False)\n",
        "            else:\n",
        "                final_dataset.to_csv('{}/{}/FS3/dataset{}.csv'.format(output_path, out_folder_name, win_size), sep='\\t',\n",
        "                                     index=False)\n",
        "#################################################################\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XEYsoipmzQ0l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Preprocessing(dataset_path=pathtodata, output_path=pathtodata, overlapping=0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NG-_GW6NUDkT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "from matplotlib.patches import Patch\n",
        "from sklearn.model_selection import (LeaveOneGroupOut, ShuffleSplit)\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "np.random.seed(1)\n",
        "\n",
        "def plot_group_class(classes, groups):\n",
        "\n",
        "    fig, ax = plt.subplots()\n",
        "    ax.scatter(range(len(groups)),  [.5] * len(groups), c=groups, marker='_',\n",
        "               lw=50,cmap=plt.cm.tab20)\n",
        "    ax.scatter(range(len(groups)),  [3.5] * len(groups), c=classes, marker='_',\n",
        "               lw=50,cmap=plt.cm.tab20b)\n",
        "    ax.set(ylim=[-1, 5], yticks=[.5, 3.5],\n",
        "           yticklabels=['Subject', 'Class'], xlabel=\"Sample index\")\n",
        "\n",
        "    ax.legend([Patch(color='navy')],\n",
        "              ['Dominant class'], loc=(1.003,.94))\n",
        "    plt.tight_layout()\n",
        "    fig.subplots_adjust(right=.75)\n",
        "\n",
        "    #project_root = os.path.dirname(os.path.dirname(__file__))\n",
        "    output_folder = os.path.join(pathtodata, 'Figures')\n",
        "    plt.savefig('{}/Class_subject.png'.format(output_folder))\n",
        "\n",
        "\n",
        "def plot_cv_indices(cv, X, y, group, ax, n_splits, lw=10):\n",
        "\n",
        "    splits = cv.split(X=X, y=y, groups=group)\n",
        "\n",
        "    for index, (training, test) in enumerate(splits):\n",
        "        indices = np.array([np.nan] * len(X))\n",
        "        indices[test] = 1\n",
        "        indices[training] = 0\n",
        "        ax.scatter(range(len(indices)), [index + .5] * len(indices),\n",
        "                   c=indices, marker='_', lw=lw, cmap=plt.cm.coolwarm\n",
        "                   )\n",
        "    ax.scatter(range(len(X)), [index + 1.5] * len(X),\n",
        "               c=y, marker='_', lw=lw, cmap=plt.cm.tab20)\n",
        "\n",
        "    ax.scatter(range(len(X)), [index + 2.5] * len(X),\n",
        "               c=group, marker='_', lw=lw, cmap=plt.cm.tab20)\n",
        "\n",
        "    if(isinstance(cv,LeaveOneGroupOut)):\n",
        "      n_splits=cv.get_n_splits(groups=group)\n",
        "\n",
        "    yticklabels = list(range(n_splits)) + ['class', 'subject']\n",
        "    ax.set(yticks=np.arange(n_splits+2) + .5, yticklabels=yticklabels,\n",
        "           xlabel='Sample index', ylabel=\"CV iteration\",\n",
        "           ylim=[n_splits+2.2, -.2], xlim=[0, len(X)])\n",
        "  \n",
        "    return ax\n",
        "#################################################################\n",
        "\n",
        "\n",
        "\n",
        "def plot_cv(dataset,CVs,n_splits):\n",
        "\n",
        "    if(len(CVs)==0):\n",
        "        raise  ValueError('There is any CV to plot.')\n",
        "\n",
        "    dataset = pd.read_csv(dataset, sep='\\t')\n",
        "\n",
        "    groups = dataset['group'].values.ravel()\n",
        "\n",
        "    gh = dataset['group'].value_counts(sort=True)\n",
        "    X = dataset.iloc[:, 1:-1].values\n",
        "\n",
        "    Y = dataset.iloc[:, dataset.shape[1] - 1].values\n",
        "\n",
        "    output_folder = os.path.join(pathtodata, 'Non-overlapping_windowed')\n",
        "\n",
        "    for cv in CVs:\n",
        "        if (cv==LeaveOneGroupOut):\n",
        "            cur_cv=cv()\n",
        "\n",
        "        else:\n",
        "            cur_cv=cv(n_splits=n_splits)\n",
        "\n",
        "        fig_name = type(cur_cv).__name__\n",
        "        fig, ax = plt.subplots(figsize=(8, 5))\n",
        "        plot_cv_indices(cv=cur_cv,X=X,y=Y,group=groups,ax=ax,n_splits=n_splits)\n",
        "\n",
        "        ax.legend([Patch(color='r'), Patch(color='b')],\n",
        "                  ['Testing set', 'Training set'], loc=(1.02, .8))\n",
        "\n",
        "        plt.tight_layout()\n",
        "        fig.subplots_adjust(right=.7)\n",
        "        plt.savefig('{}/{}.png'.format(output_folder,fig_name))\n",
        "\n",
        "    return True\n",
        "\n",
        "def test_plot_cv():\n",
        "  assert plot_cv\n",
        "#################################################################\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e16BbKjBzWqa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## Code starts here\n",
        "# This function reads the dataset0.5.cvs from /Data folder and plot the classes and subjects and also the user specified\n",
        "# Cross-validation process and save in /Figures Folder\n",
        "\n",
        "cvs = [LeaveOneGroupOut,ShuffleSplit]\n",
        "import os\n",
        "\n",
        "plot_cv(dataset=pathtodata+'Non-overlapping_windowed/FS1/dataset0.25.csv',CVs=cvs,n_splits=10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mNkfi-EsZsWb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#################################################################\n",
        "def plot_csv(csv_file, ax):\n",
        "    colors = {'NB': 'green', 'KNN': 'orange', 'DT': 'blue', 'NCC': 'r'}\n",
        "    results = pd.read_csv(csv_file)\n",
        "\n",
        "    windows = results.pop('window-size')\n",
        "\n",
        "    for col in results:\n",
        "        max = results[col].idxmax()\n",
        "        ax.plot(windows, results[col], label=col, c=colors[col.strip()])\n",
        "        ax.plot(windows[max], results[col][max], 'r*', label='peak')\n",
        "    return ax\n",
        "\n",
        "#################################################################\n",
        "def plot_results(path):\n",
        "    folders = list(filter(lambda x: os.path.isdir(os.path.join(path, x)), os.listdir(path)))\n",
        "\n",
        "    for folder in folders:\n",
        "        p = os.path.join(path, folder)\n",
        "\n",
        "        files = glob.glob('{0}/*.csv'.format(p))\n",
        "\n",
        "        if not files:\n",
        "            continue\n",
        "\n",
        "        for file in files:\n",
        "            files_name = os.path.splitext(os.path.basename(file))[0]\n",
        "\n",
        "            if ('non' in folder):\n",
        "\n",
        "                figure_title = '{}-non-overlapping'.format(files_name)\n",
        "            else:\n",
        "\n",
        "                figure_title = '{}-overlapping'.format(files_name)\n",
        "\n",
        "            fig, ax = plt.subplots()\n",
        "\n",
        "            plot_csv(file, ax)\n",
        "\n",
        "            fig.subplots_adjust(right=.84)\n",
        "\n",
        "            # remove duplicate labels from legend\n",
        "\n",
        "            handles, labels = ax.get_legend_handles_labels()\n",
        "            handle_list, label_list = [], []\n",
        "            for handle, label in zip(handles, labels):\n",
        "                if label not in label_list:\n",
        "                    handle_list.append(handle)\n",
        "                    label_list.append(label)\n",
        "\n",
        "            max_label_index = label_list.index('peak')\n",
        "            max_label = label_list.pop(max_label_index)\n",
        "            handle = handle_list.pop(max_label_index)\n",
        "\n",
        "            handle_list.append(handle)\n",
        "            label_list.append(max_label)\n",
        "\n",
        "            # sort to always be in a same order\n",
        "            label_list, handle_list = zip(*sorted(zip(label_list, handle_list), key=lambda t: t[0]))\n",
        "\n",
        "            ax.legend(handle_list, label_list, loc=(1.004, .72))\n",
        "\n",
        "            plt.xlabel('Windows Size (s)')\n",
        "            plt.ylabel('f1_score')\n",
        "            plt.ylim([0.2, 1])\n",
        "            #plt.title(figure_title)\n",
        "\n",
        "            plt.savefig('{}/{}.png'.format(output_folder, figure_title))\n",
        "\n",
        "    return True\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VH4nHogSzc5E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plot_results(path=input_path)\n",
        "def test_plot_results():\n",
        "    assert plot_results(input_path)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cvTnqWa2Z6CH",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    }
  ]
}