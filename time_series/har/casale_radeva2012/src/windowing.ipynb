{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"windowing.ipynb","version":"0.3.2","provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"JdSk2pE3EAqV","colab_type":"code","outputId":"dfdd6fa8-5bfd-4292-c45e-17cde315ea1e","executionInfo":{"status":"ok","timestamp":1557243451983,"user_tz":240,"elapsed":22126,"user":{"displayName":"Yonglin Zhu","photoUrl":"https://lh5.googleusercontent.com/-G1V2_VsevAQ/AAAAAAAAAAI/AAAAAAAAAFE/VKZRBJppNVk/s64/photo.jpg","userId":"13603424639229756219"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["## initial setup for google drive and colab\n","import glob\n","import importlib\n","from google.colab import drive\n","drive.mount(\"/content/gdrive\", force_remount=True)\n","import os\n","pathtodata = '/content/gdrive/My Drive/Activity Recognition from Single Chest-Mounted Accelerometer/'\n","os.chdir(pathtodata)"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Mounted at /content/gdrive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"mXbb-TD7EHuM","colab_type":"code","outputId":"9ff88567-d5b2-4714-dcad-d8845537055c","executionInfo":{"status":"error","timestamp":1557195612041,"user_tz":240,"elapsed":275243,"user":{"displayName":"Yonglin Zhu","photoUrl":"https://lh5.googleusercontent.com/-G1V2_VsevAQ/AAAAAAAAAAI/AAAAAAAAAFE/VKZRBJppNVk/s64/photo.jpg","userId":"13603424639229756219"}},"colab":{"base_uri":"https://localhost:8080/","height":119}},"source":["\n","import pandas as pd\n","import numpy as np\n","import os, sys\n","\n","sample_rate = 52  # number of observation per second based on dataset documentation\n","\n","sliding_size = int(.2 * sample_rate)  # number of skipped datapoints to start next window\n","\n","\n","def mean_crossing_rate(col):\n","    # col = np.array(values)\n","    normalized = col - col.mean()  # to make elements of array possitive or negetive\n","    return ((normalized[:-1] * col[1:]) < 0).sum()  # Zero-Crossing_rate\n","\n","\n","def FS1(window):  # only mean\n","\n","    avgs = list(window.mean()[:-1])\n","\n","    label = window.iloc[:, -1].mode()[0]  ## select the most frequent label as the label of the window\n","    avgs.append(label)\n","    return avgs\n","\n","\n","def FS2(window):  # Mean and std\n","\n","    features = []\n","    features.append(np.array(window.mean()[:-1]))\n","    features.append(np.array(window.std()[:-1]))\n","    features = np.hstack(features).tolist()\n","\n","    label = window.iloc[:, -1].mode()[0] ## select the most frequent label as the label of the window\n","\n","    features.append(label)\n","\n","    return features\n","\n","\n","def FS3(window):  # mean, std,max,min and zero-crossing-rate\n","\n","    features = []\n","    features.append(np.array(window.mean()[:-1]))\n","    features.append(np.array(window.std()[:-1]))\n","    features.append(np.array(window.min()[:-1]))\n","    features.append(np.array(window.max()[:-1]))\n","    mean_crossing = [mean_crossing_rate(window.iloc[:, i].values) for i in range(window.shape[1] - 1)]\n","    features.append(np.array(mean_crossing))\n","\n","    features = np.hstack(features).tolist()\n","\n","    label = window.iloc[:, -1].mode()[0]  ## select the most frequent label as the label of the window\n","    features.append(label)\n","    return features\n","\n","\n","def windowing_dataset(dataset, win_size, feature_extraction_function, subject_id, overlap=False):\n","    windowed_dataset = []\n","    win_count = 0\n","    if overlap:\n","        step_size = sliding_size  # for Overlapping technique\n","    else:\n","        step_size = win_size  # for Non-overlapping technique\n","\n","    for index in range(0, dataset.shape[0], step_size):\n","\n","        start = index\n","        end = start + win_size\n","\n","        if (end <= dataset.shape[0]):  # to assure all of windows are equal in size\n","            window = dataset.iloc[start:end, :].reset_index(drop=True)\n","            win_count = win_count + 1\n","            features = feature_extraction_function(window)\n","\n","            windowed_dataset.append(features)\n","\n","    final = pd.DataFrame(windowed_dataset)\n","    final.insert(0, 'group', subject_id)  # to use in Subject CV\n","    return final\n","\n","\n","def Preprocessing(dataset_path, output_path, overlapping):\n","\n","    features_functions = [FS1, FS2, FS3]\n","    win_sizes = np.linspace(.25, 3, 12, endpoint=True)\n","    for win_size in win_sizes:\n","\n","        print(\"Start for win size {}\".format(win_size))\n","        datapoints_per_window = int(win_size * sample_rate)\n","\n","        for feature_function in features_functions:\n","\n","            print(feature_function.__name__)\n","\n","            windowed_dataset = []\n","\n","            for subject in range(1, 16):\n","                file_path = dataset_path + \"{}.csv\".format(subject)\n","                #file_path = dataset_path + '/subject{0}_ideal.log'.format(subject)\n","                acc_cols = []\n","                for i in range(2, 117, 13):  # indices of accelarations\n","                    indices = list(range(i, i + 3))\n","                    acc_cols.extend(indices)\n","\n","                acc_cols.append(119)  # label index\n","\n","                tmp_db = pd.read_csv(file_path, header=1)#, usecols=acc_cols, sep='\\t')\n","                tmp_db.columns = list(range(tmp_db.shape[1]))  # re-index the columns\n","\n","                transformed_db = windowing_dataset(tmp_db, datapoints_per_window, feature_function, subject,\n","                                                   overlap=overlapping)\n","\n","                windowed_dataset.append(transformed_db)\n","\n","            final_dataset = pd.DataFrame()\n","            print(\"Merging!\")\n","            final_dataset = final_dataset.append(windowed_dataset, ignore_index=True)\n","\n","            if overlapping:\n","                out_folder_name = 'Overlapping_windowed'\n","            else:\n","                out_folder_name = 'Non-overlapping_windowed'\n","\n","            os.makedirs('{}/{}'.format(output_path, out_folder_name), exist_ok=True)\n","\n","            os.makedirs('{}/{}/FS1'.format(output_path, out_folder_name), exist_ok=True)\n","            os.makedirs('{}/{}/FS2'.format(output_path, out_folder_name), exist_ok=True)\n","            os.makedirs('{}/{}/FS3'.format(output_path, out_folder_name), exist_ok=True)\n","\n","            if (feature_function == FS1):\n","                final_dataset.to_csv('{}/{}/FS1/dataset{}.csv'.format(output_path, out_folder_name, win_size), sep='\\t',\n","                                     index=False)\n","            elif (feature_function == FS2):\n","                final_dataset.to_csv('{}/{}/FS2/dataset{}.csv'.format(output_path, out_folder_name, win_size), sep='\\t',\n","                                     index=False)\n","            else:\n","                final_dataset.to_csv('{}/{}/FS3/dataset{}.csv'.format(output_path, out_folder_name, win_size), sep='\\t',\n","                                     index=False)\n","\n","\n","\n","Preprocessing(dataset_path=pathtodata, output_path=pathtodata, overlapping=0)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Start for win size 0.25\n","FS1\n","Merging!\n","FS2\n","Merging!\n","FS3\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"NG-_GW6NUDkT","colab_type":"code","colab":{}},"source":["import numpy as np\n","import matplotlib.pyplot as plt\n","import pandas as pd\n","from matplotlib.patches import Patch\n","from sklearn.model_selection import (LeaveOneGroupOut, ShuffleSplit)\n","import warnings\n","warnings.filterwarnings(\"ignore\")\n","np.random.seed(1)\n","\n","def plot_group_class(classes, groups):\n","\n","    fig, ax = plt.subplots()\n","    ax.scatter(range(len(groups)),  [.5] * len(groups), c=groups, marker='_',\n","               lw=50,cmap=plt.cm.tab20)\n","    ax.scatter(range(len(groups)),  [3.5] * len(groups), c=classes, marker='_',\n","               lw=50,cmap=plt.cm.tab20b)\n","    ax.set(ylim=[-1, 5], yticks=[.5, 3.5],\n","           yticklabels=['Subject', 'Class'], xlabel=\"Sample index\")\n","\n","    ax.legend([Patch(color='navy')],\n","              ['Dominant class'], loc=(1.003,.94))\n","    plt.tight_layout()\n","    fig.subplots_adjust(right=.75)\n","\n","    #project_root = os.path.dirname(os.path.dirname(__file__))\n","    output_folder = os.path.join(pathtodata, 'Figures')\n","    plt.savefig('{}/Class_subject.png'.format(output_folder))\n","\n","\n","def plot_cv_indices(cv, X, y, group, ax, n_splits, lw=10):\n","\n","    splits = cv.split(X=X, y=y, groups=group)\n","\n","    for index, (training, test) in enumerate(splits):\n","\n","        indices = np.array([np.nan] * len(X))\n","        indices[test] = 1\n","        indices[training] = 0\n","\n","\n","\n","        ax.scatter(range(len(indices)), [index + .5] * len(indices),\n","                   c=indices, marker='_', lw=lw, cmap=plt.cm.coolwarm\n","                   )\n","\n","\n","    ax.scatter(range(len(X)), [index + 1.5] * len(X),\n","               c=y, marker='_', lw=lw, cmap=plt.cm.tab20)\n","\n","    ax.scatter(range(len(X)), [index + 2.5] * len(X),\n","               c=group, marker='_', lw=lw, cmap=plt.cm.tab20)\n","\n","\n","    if(isinstance(cv,LeaveOneGroupOut)):\n","      n_splits=cv.get_n_splits(groups=group)\n","\n","    yticklabels = list(range(n_splits)) + ['class', 'subject']\n","    ax.set(yticks=np.arange(n_splits+2) + .5, yticklabels=yticklabels,\n","           xlabel='Sample index', ylabel=\"CV iteration\",\n","           ylim=[n_splits+2.2, -.2], xlim=[0, len(X)])\n","  \n","    return ax\n","\n","\n","\n","def plot_cv(dataset,CVs,n_splits):\n","\n","    if(len(CVs)==0):\n","        raise  ValueError('There is any CV to plot.')\n","\n","\n","    dataset = pd.read_csv(dataset, sep='\\t')\n","\n","    groups = dataset['group'].values.ravel()\n","\n","    gh = dataset['group'].value_counts(sort=True)\n","    X = dataset.iloc[:, 1:-1].values\n","\n","    Y = dataset.iloc[:, dataset.shape[1] - 1].values\n","\n","    output_folder = os.path.join(pathtodata, 'Non-overlapping_windowed')\n","\n","    for cv in CVs:\n","\n","\n","        if (cv==LeaveOneGroupOut):\n","            cur_cv=cv()\n","\n","        else:\n","            cur_cv=cv(n_splits=n_splits)\n","\n","        fig_name = type(cur_cv).__name__\n","        fig, ax = plt.subplots(figsize=(8, 5))\n","        plot_cv_indices(cv=cur_cv,X=X,y=Y,group=groups,ax=ax,n_splits=n_splits)\n","\n","        ax.legend([Patch(color='r'), Patch(color='b')],\n","                  ['Testing set', 'Training set'], loc=(1.02, .8))\n","\n","        plt.tight_layout()\n","        fig.subplots_adjust(right=.7)\n","\n","\n","        plt.savefig('{}/{}.png'.format(output_folder,fig_name))\n","\n","    return True\n","\n","def test_plot_cv():\n","  assert plot_cv\n","#################################################################\n","## Code starts here\n","# This function reads the dataset0.5.cvs from /Data folder and plot the classes and subjects and also the user specified\n","# Cross-validation process and save in /Figures Folder\n","\n","cvs = [LeaveOneGroupOut,ShuffleSplit]\n","import os\n","\n","plot_cv(dataset=pathtodata+'Non-overlapping_windowed/FS1/dataset0.25.csv',CVs=cvs,n_splits=10)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"mNkfi-EsZsWb","colab_type":"code","colab":{}},"source":["def plot_csv(csv_file, ax):\n","    colors = {'NB': 'green', 'KNN': 'orange', 'DT': 'blue', 'NCC': 'r'}\n","    results = pd.read_csv(csv_file)\n","\n","    windows = results.pop('window-size')\n","\n","    for col in results:\n","        max = results[col].idxmax()\n","        ax.plot(windows, results[col], label=col, c=colors[col.strip()])\n","        ax.plot(windows[max], results[col][max], 'r*', label='peak')\n","\n","    return ax\n","\n","\n","def plot_results(path):\n","    folders = list(filter(lambda x: os.path.isdir(os.path.join(path, x)), os.listdir(path)))\n","\n","    for folder in folders:\n","        p = os.path.join(path, folder)\n","\n","        files = glob.glob('{0}/*.csv'.format(p))\n","\n","        if not files:\n","            continue\n","\n","        for file in files:\n","            files_name = os.path.splitext(os.path.basename(file))[0]\n","\n","            if ('non' in folder):\n","\n","                figure_title = '{}-non-overlapping'.format(files_name)\n","            else:\n","\n","                figure_title = '{}-overlapping'.format(files_name)\n","\n","            fig, ax = plt.subplots()\n","\n","            plot_csv(file, ax)\n","\n","            fig.subplots_adjust(right=.84)\n","\n","            # remove duplicate labels from legend\n","\n","            handles, labels = ax.get_legend_handles_labels()\n","            handle_list, label_list = [], []\n","            for handle, label in zip(handles, labels):\n","                if label not in label_list:\n","                    handle_list.append(handle)\n","                    label_list.append(label)\n","\n","            max_label_index = label_list.index('peak')\n","            max_label = label_list.pop(max_label_index)\n","            handle = handle_list.pop(max_label_index)\n","\n","            handle_list.append(handle)\n","            label_list.append(max_label)\n","\n","            # sort to always be in a same order\n","            label_list, handle_list = zip(*sorted(zip(label_list, handle_list), key=lambda t: t[0]))\n","\n","            ax.legend(handle_list, label_list, loc=(1.004, .72))\n","\n","            plt.xlabel('Windows Size (s)')\n","            plt.ylabel('f1_score')\n","            plt.ylim([0.2, 1])\n","            #plt.title(figure_title)\n","\n","            plt.savefig('{}/{}.png'.format(output_folder, figure_title))\n","\n","    return True\n","\n","\n","plot_results(path=input_path)\n","\n","\n","def test_plot_results():\n","    assert plot_results(input_path)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"cvTnqWa2Z6CH","colab_type":"text"},"source":[""]}]}